{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0724237-fb1e-4eb3-abf2-22db33c5e5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import sklearn\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c09ca444-db37-45f5-8e1d-65c96978c566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set device \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a70459f-1d03-4c5c-99fc-828621b4f99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set param\n",
    "batch_size = 256\n",
    "epoch = 100\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e56fcbc9-89d3-41c7-87d8-2063c5f9e47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "torch.manual_seed(1)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d4d9bbc-8332-4331-9936-72fe488aa9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dir path\n",
    "train_dir_path = \"./Week10/2021-ai-w10-p2/images/images\"\n",
    "test_dir_path = \"./Week10/2021-ai-w10-p2/test_data/test_data\"\n",
    "# submission = pd.read_csv(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2e8d016-62d8-4a38-9a0e-6e25040ce12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set custom dataset\n",
    "class myDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,split,path,transform=None):\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        if self.split == \"train\":\n",
    "            self.path = glob(os.path.join(path,\"*\",\"*\"))\n",
    "            self.path = [ x.replace(\"\\\\\",\"/\") for x in self.path]\n",
    "            self.label = [ int(x.split(\"/\")[-2]) for x in self.path]\n",
    "        else:\n",
    "            self.path = glob(os.path.join(path,\"*\"))\n",
    "            self.path = [ x.replace(\"\\\\\",\"/\") for x in self.path]\n",
    "            # sorted\n",
    "        self.len = len(self.path)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img = Image.open(self.path[index])\n",
    "        if transform is None :\n",
    "            img = np.array(img)\n",
    "            img = img.reshape(256,256,3).repeat(3,-1).transpose((0,3,1,2))\n",
    "            if self.split == \"train\":\n",
    "                return torch.Tensor(img), torch.LongTensor(self.label)\n",
    "            else:\n",
    "                return torch.Tensor(img)\n",
    "        else:\n",
    "            img = self.transpoform(img)\n",
    "            img = np.array(img)\n",
    "            if self.split == \"train\":\n",
    "                return torch.Tensor(img), torch.LongTensor(self.label)\n",
    "            else:\n",
    "                return torch.Tensor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e61c0bb4-6419-469c-8c2d-774cddc05df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definde transform\n",
    "transform = transforms.Compose([transforms.Resize((256,256)),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc23940f-b940-4ce1-9839-72b58605a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use dataset\n",
    "train_dataset = myDataset(\"train\",train_dir_path,transform)\n",
    "test_dataset = myDataset(\"test\",test_dir_path,transform)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "28ff1739-3b37-4017-abb2-0e0e3d5c22d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not use dataset\n",
    "train = pd.read_csv(\"./2021-ai-midterm-p5/train.csv\")\n",
    "test = pd.read_csv(\"./2021-ai-midterm-p5/test.csv\")\n",
    "submission = pd.read_csv(\"./2021-ai-midterm-p5/submit_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4e5ec3f5-e737-43d8-b86c-61fc556736e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4788 entries, 0 to 4787\n",
      "Data columns (total 23 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   index             4788 non-null   int64  \n",
      " 1   Unnamed: 0        4788 non-null   int64  \n",
      " 2   customerID        4788 non-null   object \n",
      " 3   gender            4788 non-null   object \n",
      " 4   SeniorCitizen     4788 non-null   int64  \n",
      " 5   Partner           4788 non-null   object \n",
      " 6   Dependents        4788 non-null   object \n",
      " 7   tenure            4788 non-null   int64  \n",
      " 8   PhoneService      4788 non-null   object \n",
      " 9   MultipleLines     4788 non-null   object \n",
      " 10  InternetService   4788 non-null   object \n",
      " 11  OnlineSecurity    4788 non-null   object \n",
      " 12  OnlineBackup      4788 non-null   object \n",
      " 13  DeviceProtection  4788 non-null   object \n",
      " 14  TechSupport       4788 non-null   object \n",
      " 15  StreamingTV       4788 non-null   object \n",
      " 16  StreamingMovies   4788 non-null   object \n",
      " 17  Contract          4788 non-null   object \n",
      " 18  PaperlessBilling  4788 non-null   object \n",
      " 19  PaymentMethod     4788 non-null   object \n",
      " 20  MonthlyCharges    4788 non-null   float64\n",
      " 21  TotalCharges      4788 non-null   object \n",
      " 22  Churn             4788 non-null   object \n",
      "dtypes: float64(1), int64(4), object(18)\n",
      "memory usage: 860.5+ KB\n",
      "None\n",
      "   index  Unnamed: 0  customerID  gender  SeniorCitizen Partner Dependents  \\\n",
      "0      0        1869  7010-BRBUU    Male              0     Yes        Yes   \n",
      "1      1        4528  9688-YGXVR  Female              0      No         No   \n",
      "2      2        6344  9286-DOJGF  Female              1     Yes         No   \n",
      "3      3        6739  6994-KERXL    Male              0      No         No   \n",
      "4      4         432  2181-UAESM    Male              0      No         No   \n",
      "\n",
      "   tenure PhoneService MultipleLines  ...     DeviceProtection  \\\n",
      "0      72          Yes           Yes  ...  No internet service   \n",
      "1      44          Yes            No  ...                  Yes   \n",
      "2      38          Yes           Yes  ...                   No   \n",
      "3       4          Yes            No  ...                   No   \n",
      "4       2          Yes            No  ...                  Yes   \n",
      "\n",
      "           TechSupport          StreamingTV      StreamingMovies  \\\n",
      "0  No internet service  No internet service  No internet service   \n",
      "1                   No                  Yes                   No   \n",
      "2                   No                   No                   No   \n",
      "3                   No                   No                  Yes   \n",
      "4                   No                   No                   No   \n",
      "\n",
      "         Contract PaperlessBilling              PaymentMethod MonthlyCharges  \\\n",
      "0        Two year               No    Credit card (automatic)          24.10   \n",
      "1  Month-to-month              Yes    Credit card (automatic)          88.15   \n",
      "2  Month-to-month              Yes  Bank transfer (automatic)          74.95   \n",
      "3  Month-to-month              Yes           Electronic check          55.90   \n",
      "4  Month-to-month               No           Electronic check          53.45   \n",
      "\n",
      "  TotalCharges Churn  \n",
      "0      1734.65    No  \n",
      "1       3973.2    No  \n",
      "2      2869.85   Yes  \n",
      "3        238.5    No  \n",
      "4        119.5    No  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1198 entries, 0 to 1197\n",
      "Data columns (total 22 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   index             1198 non-null   int64  \n",
      " 1   Unnamed: 0        1198 non-null   int64  \n",
      " 2   customerID        1198 non-null   object \n",
      " 3   gender            1198 non-null   object \n",
      " 4   SeniorCitizen     1198 non-null   int64  \n",
      " 5   Partner           1198 non-null   object \n",
      " 6   Dependents        1198 non-null   object \n",
      " 7   tenure            1198 non-null   int64  \n",
      " 8   PhoneService      1198 non-null   object \n",
      " 9   MultipleLines     1198 non-null   object \n",
      " 10  InternetService   1198 non-null   object \n",
      " 11  OnlineSecurity    1198 non-null   object \n",
      " 12  OnlineBackup      1198 non-null   object \n",
      " 13  DeviceProtection  1198 non-null   object \n",
      " 14  TechSupport       1198 non-null   object \n",
      " 15  StreamingTV       1198 non-null   object \n",
      " 16  StreamingMovies   1198 non-null   object \n",
      " 17  Contract          1198 non-null   object \n",
      " 18  PaperlessBilling  1198 non-null   object \n",
      " 19  PaymentMethod     1198 non-null   object \n",
      " 20  MonthlyCharges    1198 non-null   float64\n",
      " 21  TotalCharges      1198 non-null   float64\n",
      "dtypes: float64(2), int64(4), object(16)\n",
      "memory usage: 206.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# check csv\n",
    "print(train.info())\n",
    "print(train.head())\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "546ea422-b1f7-4c00-b48d-40b84e35b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "\n",
    "# object to int\n",
    "for col in train.columns:\n",
    "    if train[col].isnull().sum() != 0 : # 결측값이 있다면\n",
    "        #최빈값으로 처리\n",
    "        train[col] = train[col].fillna(train[col].mode()[0]) \n",
    "for col in test.columns:\n",
    "    if test[col].isnull().sum() != 0:\n",
    "        test[col] = test[col].fillna(test[col].mode()[0])\n",
    "\n",
    "# object to label\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for col in test.columns:\n",
    "    if test[col].dtype == \"object\" or train[col].dtype ==\"object\":\n",
    "        test[col] = test[col].astype(str)\n",
    "        train[col] = train[col].astype(str)\n",
    "        total = pd.concat([test[col],train[col]],axis=0)\n",
    "        le.fit(total)\n",
    "        test[col] = le.transform(test[col])\n",
    "        train[col] = le.transform(train[col])\n",
    "train['Churn'] = le.fit_transform(train['Churn'])\n",
    "\n",
    "\n",
    "# drop unuse column\n",
    "# train, val  = torch.utils.data.random_split(dataset,[7,3],torch.Generator().manual_seed(42))\n",
    "train_x = np.array(train.drop(['index','Unnamed: 0','Churn','customerID'],axis=1))\n",
    "test_x = np.array(test.drop(['index','Unnamed: 0','customerID'],axis=1))\n",
    "train_y = np.array(train['Churn'])\n",
    "\n",
    "# scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "test_x = scaler.transform(test_x)\n",
    "\n",
    "# load data on tensor\n",
    "train_x = torch.Tensor(train_x).to(device)\n",
    "test_x = torch.Tensor(test_x).to(device)\n",
    "train_y = torch.Tensor(train_y).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "88158dbb-45ab-4d20-a442-6b2343df24f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4788, 19])\n",
      "torch.Size([4788])\n",
      "torch.Size([1198, 19])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# check data shape\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(len(torch.unique(train_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "12cb208f-63ae-4d28-8326-47a9c34d03f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mSimpleImputer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmissing_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstrategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0madd_indicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Imputation transformer for completing missing values.\n",
       "\n",
       "Read more in the :ref:`User Guide <impute>`.\n",
       "\n",
       ".. versionadded:: 0.20\n",
       "   `SimpleImputer` replaces the previous `sklearn.preprocessing.Imputer`\n",
       "   estimator which is now removed.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "missing_values : int, float, str, np.nan or None, default=np.nan\n",
       "    The placeholder for the missing values. All occurrences of\n",
       "    `missing_values` will be imputed. For pandas' dataframes with\n",
       "    nullable integer dtypes with missing values, `missing_values`\n",
       "    should be set to `np.nan`, since `pd.NA` will be converted to `np.nan`.\n",
       "\n",
       "strategy : string, default='mean'\n",
       "    The imputation strategy.\n",
       "\n",
       "    - If \"mean\", then replace missing values using the mean along\n",
       "      each column. Can only be used with numeric data.\n",
       "    - If \"median\", then replace missing values using the median along\n",
       "      each column. Can only be used with numeric data.\n",
       "    - If \"most_frequent\", then replace missing using the most frequent\n",
       "      value along each column. Can be used with strings or numeric data.\n",
       "      If there is more than one such value, only the smallest is returned.\n",
       "    - If \"constant\", then replace missing values with fill_value. Can be\n",
       "      used with strings or numeric data.\n",
       "\n",
       "    .. versionadded:: 0.20\n",
       "       strategy=\"constant\" for fixed value imputation.\n",
       "\n",
       "fill_value : string or numerical value, default=None\n",
       "    When strategy == \"constant\", fill_value is used to replace all\n",
       "    occurrences of missing_values.\n",
       "    If left to the default, fill_value will be 0 when imputing numerical\n",
       "    data and \"missing_value\" for strings or object data types.\n",
       "\n",
       "verbose : integer, default=0\n",
       "    Controls the verbosity of the imputer.\n",
       "\n",
       "copy : boolean, default=True\n",
       "    If True, a copy of X will be created. If False, imputation will\n",
       "    be done in-place whenever possible. Note that, in the following cases,\n",
       "    a new copy will always be made, even if `copy=False`:\n",
       "\n",
       "    - If X is not an array of floating values;\n",
       "    - If X is encoded as a CSR matrix;\n",
       "    - If add_indicator=True.\n",
       "\n",
       "add_indicator : boolean, default=False\n",
       "    If True, a :class:`MissingIndicator` transform will stack onto output\n",
       "    of the imputer's transform. This allows a predictive estimator\n",
       "    to account for missingness despite imputation. If a feature has no\n",
       "    missing values at fit/train time, the feature won't appear on\n",
       "    the missing indicator even if there are missing values at\n",
       "    transform/test time.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "statistics_ : array of shape (n_features,)\n",
       "    The imputation fill value for each feature.\n",
       "    Computing statistics can result in `np.nan` values.\n",
       "    During :meth:`transform`, features corresponding to `np.nan`\n",
       "    statistics will be discarded.\n",
       "\n",
       "indicator_ : :class:`~sklearn.impute.MissingIndicator`\n",
       "    Indicator used to add binary indicators for missing values.\n",
       "    ``None`` if add_indicator is False.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "IterativeImputer : Multivariate imputation of missing values.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> from sklearn.impute import SimpleImputer\n",
       ">>> imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
       ">>> imp_mean.fit([[7, 2, 3], [4, np.nan, 6], [10, 5, 9]])\n",
       "SimpleImputer()\n",
       ">>> X = [[np.nan, 2, 3], [4, np.nan, 6], [10, np.nan, 9]]\n",
       ">>> print(imp_mean.transform(X))\n",
       "[[ 7.   2.   3. ]\n",
       " [ 4.   3.5  6. ]\n",
       " [10.   3.5  9. ]]\n",
       "\n",
       "Notes\n",
       "-----\n",
       "Columns which only contained missing values at :meth:`fit` are discarded\n",
       "upon :meth:`transform` if strategy is not \"constant\".\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\python39\\lib\\site-packages\\sklearn\\impute\\_base.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b21d817-f129-4bc4-bc8f-ec5155ab8063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb113367-ccf5-492d-a59c-90bee70fbe8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
