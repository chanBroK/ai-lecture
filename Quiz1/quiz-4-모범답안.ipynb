{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "/kaggle/input/2021-ai-quiz1-p4/train.csv\n",
    "/kaggle/input/2021-ai-quiz1-p4/test.csv\n",
    "/kaggle/input/2021-ai-quiz1-p4/submit_sample.csv\n",
    "# 따릉이 예측문제\n",
    "train = pd.read_csv(\"../input/2021-ai-quiz1-p4/train.csv\")\n",
    "test = pd.read_csv(\"../input/2021-ai-quiz1-p4/test.csv\")\n",
    "submit = pd.read_csv(\"../input/2021-ai-quiz1-p4/submit_sample.csv\")\n",
    "train.head()\n",
    "id\thour\thour_bef_temperature\thour_bef_precipitation\thour_bef_windspeed\thour_bef_humidity\thour_bef_visibility\thour_bef_ozone\thour_bef_pm10\thour_bef_pm2.5\tcount\n",
    "0\t3\t20\t16.3\t1.0\t1.5\t89.0\t576.0\t0.027\t76.0\t33.0\t49.0\n",
    "1\t6\t13\t20.1\t0.0\t1.4\t48.0\t916.0\t0.042\t73.0\t40.0\t159.0\n",
    "2\t7\t6\t13.9\t0.0\t0.7\t79.0\t1382.0\t0.033\t32.0\t19.0\t26.0\n",
    "3\t8\t23\t8.1\t0.0\t2.7\t54.0\t946.0\t0.040\t75.0\t64.0\t57.0\n",
    "4\t9\t18\t29.5\t0.0\t4.8\t7.0\t2000.0\t0.057\t27.0\t11.0\t431.0\n",
    "test.head()\n",
    "id\thour\thour_bef_temperature\thour_bef_precipitation\thour_bef_windspeed\thour_bef_humidity\thour_bef_visibility\thour_bef_ozone\thour_bef_pm10\thour_bef_pm2.5\n",
    "0\t1655\t4\t14.6\t0.0\t0.6\t49.0\t2000.0\t0.014\t41.0\t27.0\n",
    "1\t1657\t20\t21.8\t0.0\t4.4\t40.0\t2000.0\t0.048\t35.0\t19.0\n",
    "2\t1660\t22\t18.3\t0.0\t1.0\t37.0\t970.0\t0.032\t169.0\t38.0\n",
    "3\t1662\t7\t13.2\t0.0\t0.6\t85.0\t431.0\t0.023\t50.0\t39.0\n",
    "4\t1663\t8\t8.9\t0.0\t0.9\t77.0\t613.0\t0.005\t82.0\t40.0\n",
    "submit.head()\n",
    "id\tcount\n",
    "0\t0\t0\n",
    "1\t1\t0\n",
    "2\t2\t0\n",
    "3\t3\t0\n",
    "4\t4\t0\n",
    "#필요없는 column들을 제거하고 x_train, y_train, x_test 셋팅\n",
    "x_train = train.drop(['id', 'count'], axis = 1)\n",
    "y_train = train['count']\n",
    "x_test = test.drop('id', axis = 1)\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.cuda\n",
    "# 정규화를 위한 sklearn 호출 후 정규화 진행\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = pd.DataFrame(sc.fit_transform(x_train))\n",
    "x_test = pd.DataFrame(sc.transform(x_test))\n",
    "#tensor로 변환\n",
    "x_train = torch.FloatTensor(x_train.values).cuda()\n",
    "y_train = torch.FloatTensor(y_train.values).cuda()\n",
    "x_test = torch.FloatTensor(x_test.values).cuda()\n",
    "# linear의 입력 노드 확인을 위한 shape 호출\n",
    "print(x_train.shape)\n",
    "torch.Size([1000, 9])\n",
    "linear1 = torch.nn.Linear(9, 30, bias = True)\n",
    "linear2 = torch.nn.Linear(30, 30, bias = True)\n",
    "linear3 = torch.nn.Linear(30, 1, bias = True)\n",
    "relu = torch.nn.ReLU()\n",
    "\n",
    "# layer로 linear 함수 사용\n",
    "# 활성화 함수 relu 함수 사용\n",
    "model = torch.nn.Sequential(linear1, relu,\n",
    "                           linear2, relu, \n",
    "                           linear3).cuda()\n",
    "# layer 작동 순서\n",
    "# 모델 학습\n",
    "\n",
    "loss = torch.nn.MSELoss().cuda()\n",
    "# 회귀 문제이기 때문에 loss 함수로 MSELoss를 사용\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)\n",
    "# optimizer로 SGD 사용\n",
    "\n",
    "nb_epochs = 5000\n",
    "\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    hypothesis = model(x_train)\n",
    "    \n",
    "    cost = loss(hypothesis, y_train.unsqueeze(1))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(epoch, cost.item())\n",
    "        \n",
    "# SGD를 사용할때 처음 cost 값이 크게 나와 lr를 0.1에서 0.001까지 줄여가며 조절\n",
    "# cost가 유의미하게 크게 줄어드는것을 고려하여 epoch를 1000에서 3000, 5000, 으로 늘림\n",
    "0 19312.513671875\n",
    "100 3104.072265625\n",
    "200 2342.246826171875\n",
    "300 1899.012939453125\n",
    "400 2171.9755859375\n",
    "500 1832.5203857421875\n",
    "600 1659.43212890625\n",
    "700 1576.8045654296875\n",
    "800 1458.279052734375\n",
    "900 1401.5426025390625\n",
    "1000 1301.5474853515625\n",
    "1100 1256.3345947265625\n",
    "1200 1236.3128662109375\n",
    "1300 1080.5673828125\n",
    "1400 1088.3709716796875\n",
    "1500 1021.0570678710938\n",
    "1600 977.6937866210938\n",
    "1700 972.03857421875\n",
    "1800 903.642822265625\n",
    "1900 839.2060546875\n",
    "2000 871.184814453125\n",
    "2100 769.9696655273438\n",
    "2200 826.9214477539062\n",
    "2300 725.1409301757812\n",
    "2400 839.95751953125\n",
    "2500 794.619873046875\n",
    "2600 780.0992431640625\n",
    "2700 639.16748046875\n",
    "2800 703.5933837890625\n",
    "2900 634.4940185546875\n",
    "3000 617.7144775390625\n",
    "3100 639.7200317382812\n",
    "3200 680.9598388671875\n",
    "3300 618.779541015625\n",
    "3400 595.28955078125\n",
    "3500 592.1597900390625\n",
    "3600 616.5580444335938\n",
    "3700 545.1934814453125\n",
    "3800 523.733154296875\n",
    "3900 555.3435668945312\n",
    "4000 603.1419677734375\n",
    "4100 564.524658203125\n",
    "4200 478.7824401855469\n",
    "4300 538.4795532226562\n",
    "4400 464.1126403808594\n",
    "4500 529.2308959960938\n",
    "4600 411.4157409667969\n",
    "4700 382.4579162597656\n",
    "4800 469.8476867675781\n",
    "4900 410.4792175292969\n",
    "5000 436.9608154296875\n",
    "# x_test로 모델 예측\n",
    "\n",
    "with torch.no_grad():\n",
    "    hypothesis = model(x_test)\n",
    "    predict = hypothesis\n",
    "    submit['count'] = predict.detach().cpu().numpy().astype(float)\n",
    "    print(submit)\n",
    "      id       count\n",
    "0      0   13.256634\n",
    "1      1  261.648926\n",
    "2      2  142.918869\n",
    "3      3   25.740717\n",
    "4      4   74.538879\n",
    "..   ...         ...\n",
    "322  322   28.640741\n",
    "323  323   32.878277\n",
    "324  324   44.834766\n",
    "325  325  192.338501\n",
    "326  326  187.779282\n",
    "\n",
    "[327 rows x 2 columns]\n",
    "# 예측값 제출\n",
    "submit.to_csv('submission.csv', index = False)\n",
    "# 따릉이 사용자 예측문제를 DNN 방식으로 풀어보았습니다.\n",
    "# 3개의 Linear layer와 relu함수를 활성화 함수로 사용하였고\n",
    "# optimizer는 SGD를 사용하였습니다. 여기서 lr은 cost가 수렴하는 모습을 보일때 까지 0.1에서 0.001까지 조절하게 되었습니다.\n",
    "# cost가 유의미하게 크게 줄어드는것을 고려하여 epoch를 1000에서 3000, 5000 으로 늘려서 모델을 학습시켰습니다.\n",
    "# 회귀 문제이기 때문에 loss 함수로 MSELoss를 사용하였습니다.\n",
    "# optimizer를 Adam으로 사용하고 dropout 기법 또한 사용한다면 큰 성능 향상이 있을것입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
