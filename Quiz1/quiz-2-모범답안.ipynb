{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# 데이터 로드\n",
    "train = pd.read_csv('/kaggle/input/2021-ai-quiz1-p2/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/2021-ai-quiz1-p2/test.csv')\n",
    "submit = pd.read_csv('/kaggle/input/2021-ai-quiz1-p2/submit_sample.csv')\n",
    "\n",
    "# 불필요한 열 제거 및 라벨 분리\n",
    "label = train['8']\n",
    "train = train.drop(['Unnamed: 0','8'],axis=1)\n",
    "test = test.drop(['Unnamed: 0','8'],axis=1)\n",
    "print(train.shape, test.shape, label.shape)\n",
    "\n",
    "# standard scaler 를 이용한 전처리\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_std = scaler.fit_transform(train)\n",
    "test_std = scaler.transform(test)\n",
    "# 랜덤 시드 고정 및 gpu 설정\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# 텐서로 변환\n",
    "X = torch.FloatTensor(train_std).to(device)\n",
    "Y = torch.FloatTensor(label).to(device)\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# 모델 설정 및 활성화 함수 설정\n",
    "linear1 = nn.Linear(8,1,bias=True)\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "model = nn.Sequential(linear1, sigmoid).to(device)\n",
    "# 옵티마이저 및 손실함수 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.BCELoss().to(device)\n",
    "# 모델 학습\n",
    "model.train()\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs + 1):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X)\n",
    "    loss = loss_fn(output, Y.unsqueeze(1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: {:4d}, Cost: {:6f}\".format(epoch, loss.item()))\n",
    "Epoch:    0, Cost: 0.715863\n",
    "Epoch:  100, Cost: 0.608985\n",
    "Epoch:  200, Cost: 0.558321\n",
    "Epoch:  300, Cost: 0.530702\n",
    "Epoch:  400, Cost: 0.513910\n",
    "Epoch:  500, Cost: 0.502915\n",
    "Epoch:  600, Cost: 0.495343\n",
    "Epoch:  700, Cost: 0.489937\n",
    "Epoch:  800, Cost: 0.485973\n",
    "Epoch:  900, Cost: 0.483007\n",
    "Epoch: 1000, Cost: 0.480751\n",
    "# 텐서로 변환\n",
    "X_test = torch.FloatTensor(test_std).to(device)\n",
    "# 모델 평가\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predict = model(X_test)\n",
    "# 이진 분류를 위해 0,1 값으로 변환\n",
    "pred = (predict.cpu() >= torch.FloatTensor([0.5])).to(int)\n",
    "# 제출\n",
    "submit['Label'] = pred.detach().numpy()\n",
    "submit.to_csv(\"submit-2.csv\",index=False)\n",
    "분석 결과\n",
    "standard scaler를 이용해 데이터를 전처리하였을 때 더 높은 성능을 볼 수 있었다. 또한 learning rate가 너무 작으면 학습이 잘 안되었다. epoch를 크게 키워도 큰 성능 차이는 없었고 비슷한 cost 수준에서 계속 수렴하는 듯 했다. 오히려 learning rate를 조작하였을 때 성능 차이를 볼 수 있었다. 그리고 레이어를 쌓을 수록 성능이 안좋아졌다. 한개의 레이어만 있을 때 가장 높은 성능이 나왔고 그렇지 않을 때에는 오히려 과적합 문제가 있었던것 같았다. 그리고 첫번째 아이디 열을 제거했을 때 더 높은 성능이 나왔다. 불필요한 데이터를 제거해야한다.\n",
    "\n",
    " \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
