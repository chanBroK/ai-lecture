{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86ae24bf-8998-48f9-b20a-94ae2d702a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# cuda error 표시 안될 때 \n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d73a58c1-c23c-49e2-acb8-f32b0c4d9c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import sklearn\n",
    "import random\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b0d0f0b-6a5f-4568-918a-2a435d9d557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting seed\n",
    "torch.manual_seed(1)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(1)\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db7a86fa-af38-4423-beb4-547125b2ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting param\n",
    "lr = 0.001\n",
    "epochs = 50\n",
    "batch_size= 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbe8e132-ec38-40fb-b346-acac75ad1700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading \n",
    "transform = transforms.Compose([transforms.Resize((32,32)),transforms.ToTensor(),transforms.Normalize((0.5),(0.5))])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='MNIST_data/',train=True,transform=transform,download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='MNIST_data/',train=False,transform=transform,download=True)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size= batch_size, shuffle= True, drop_last=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size= batch_size, shuffle= False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "acaf512a-c65f-42fe-a998-a820b29c294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Model\n",
    "class LeNet5(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        ##\n",
    "        super(LeNet5,self).__init__()\n",
    "        ##\n",
    "        \n",
    "        self.c1 = torch.nn.Conv2d(in_channels=1,out_channels=6,kernel_size=5,stride=1,padding=0)        \n",
    "        self.s2 = torch.nn.AvgPool2d(kernel_size =2, stride =2)\n",
    "        self.c3 = torch.nn.Conv2d(in_channels=6,out_channels=16,kernel_size=5,stride=1,padding=0)        \n",
    "        # Pooling Layer의 인자로는 kernel size 와 stride 만 들어간다.\n",
    "        self.s4 = torch.nn.AvgPool2d( kernel_size =2, stride =2)\n",
    "        # FC하는 과정은 Conv2d 보다 Linear 사용\n",
    "#         self.c5 = torch.nn.Conv2d(in_channels=16,out_channels=120)\n",
    "        self.c5= torch.nn.Linear(in_features=16*5*5,out_features=120)\n",
    "        self.f6 = torch.nn.Linear(in_features=120,out_features=84)\n",
    "        self.output = torch.nn.Linear(in_features=84, out_features=10)\n",
    "        \n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        torch.nn.init.xavier_normal_(self.output.weight)\n",
    "        torch.nn.init.xavier_normal_(self.f6.weight)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.c1(x)\n",
    "        out = self.tanh(out)\n",
    "        out = self.s2(out)\n",
    "        out = self.c3(out)\n",
    "        out = self.tanh(out)\n",
    "        out = self.s4(out)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.c5(out)\n",
    "        out = self.tanh(out)\n",
    "        out = self.f6(out)\n",
    "        out = self.tanh(out)\n",
    "        out = self.output(out)\n",
    "#         out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6dad4589-56f2-43bc-93f8-cdc6651b7d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare train\n",
    "model = LeNet5().to(device)\n",
    "optim = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "42213f22-c923-465b-a271-83e1e1f336cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader):\n",
    "    model.train()\n",
    "    sum_cost = 0\n",
    "    sum_correct = 0\n",
    "    for data,target in data_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "#         print(data.shape, output.shape, target.shape)\n",
    "        cost = loss(output,target)\n",
    "        sum_cost += cost.item()\n",
    "        predict = torch.argmax(output,dim=1)\n",
    "        correct = (predict == target).sum().item()\n",
    "        sum_correct += correct\n",
    "        optim.zero_grad()\n",
    "        cost.backward()\n",
    "        optim.step()\n",
    "    return sum_cost/len(data_loader.dataset),sum_correct/len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2110d7f0-687a-4061-b345-ced56c807f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.008751852603753408 22.093333333333334\n",
      "1 0.008123514872789383 52.195\n",
      "2 0.007263164158662161 60.980000000000004\n",
      "3 0.006252721240123113 66.74666666666667\n",
      "4 0.00531728232105573 71.27\n",
      "5 0.004574147472778956 74.66166666666668\n",
      "6 0.004018625596165657 77.30666666666667\n",
      "7 0.003603675306836764 79.42\n",
      "8 0.0032881356606880826 80.96166666666666\n",
      "9 0.0030418980528910955 82.28333333333333\n",
      "10 0.002843828555941582 83.16\n",
      "11 0.0026831516524155933 83.89999999999999\n",
      "12 0.0025507385164499283 84.52333333333333\n",
      "13 0.002437978074947993 85.00333333333333\n",
      "14 0.0023411030704776447 85.40333333333334\n",
      "15 0.0022568170701464016 85.76\n",
      "16 0.0021836641907691957 86.12666666666667\n",
      "17 0.0021177221993605297 86.41\n",
      "18 0.0020595117355386417 86.70166666666667\n",
      "19 0.002008778993288676 86.92166666666667\n",
      "20 0.001959413293500741 87.17833333333334\n",
      "21 0.0019163584594925245 87.40333333333334\n",
      "22 0.0018764892001946767 87.59166666666667\n",
      "23 0.0018411386708418527 87.795\n",
      "24 0.0018045106828212738 87.94999999999999\n",
      "25 0.0017736833194891611 88.11\n",
      "26 0.0017444890603423118 88.26833333333333\n",
      "27 0.0017185038914283117 88.38000000000001\n",
      "28 0.001691345784564813 88.50333333333333\n",
      "29 0.001667923408250014 88.63\n",
      "30 0.0016435968731840452 88.75\n",
      "31 0.0016224376032749812 88.87666666666667\n",
      "32 0.0016026297723253568 88.99833333333333\n",
      "33 0.0015833885421355565 89.12833333333333\n",
      "34 0.0015645734623074533 89.21333333333334\n",
      "35 0.0015463424131274223 89.30833333333334\n",
      "36 0.0015294107377529145 89.425\n",
      "37 0.0015130928933620453 89.51833333333333\n",
      "38 0.0014981977810462315 89.58\n",
      "39 0.0014823972726861637 89.67500000000001\n",
      "40 0.0014680010363459586 89.74833333333333\n",
      "41 0.0014558215650419394 89.82\n",
      "42 0.0014409311016400656 89.895\n",
      "43 0.0014273638864358267 89.955\n",
      "44 0.0014151820451021194 90.04333333333334\n",
      "45 0.0014039068534970284 90.11166666666666\n",
      "46 0.0013908017675081888 90.17166666666667\n",
      "47 0.001379175593952338 90.26166666666666\n",
      "48 0.0013688211518029373 90.32166666666667\n",
      "49 0.001357761386781931 90.39\n",
      "endtime = 469.0304582118988\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "cur_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    cost,acc = train(model,train_dataloader)\n",
    "    print(epoch,cost,acc*100)\n",
    "print(\"endtime =\",time.time() - cur_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbee6b3-084c-428f-9c98-a6ec79ca2321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model,data_loader):\n",
    "    model.eval()\n",
    "    sum_correct = 0\n",
    "    for data in data_loader:\n",
    "        output = model(data[0].to(device))\n",
    "        target = data[1].to(device)\n",
    "        predict = torch.argmax(output, dim=1)\n",
    "        correct = (predict == target).sum().item()\n",
    "        sum_correct += correct\n",
    "    return sum_correct/len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d2a3f-aa27-4039-acba-f65648c8a3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(validate(model,train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fb1414-ed68-4ba8-8bc4-006cb7500deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Tensor on Dataset\n",
    "test_dataset = torch.utils.data.TensorDataset(x_test)\n",
    "test_data_loader = DataLoader(dataset=test_dataset,batch_size= batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34a63b2-d7cc-4433-8cca-2b0074c1c99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,data_loader):\n",
    "    model.eval()\n",
    "    predict_array =[]\n",
    "    for data in data_loader:\n",
    "        output = model(data[0].to(device))\n",
    "        predict = torch.argmax(output,dim = 1)\n",
    "        predict_array += np.array(predict.cpu().detach()).tolist()\n",
    "    return predict_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d84bdd-a0a9-4896-931f-2b8365b4941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predict = predict(model,test_data_loader)\n",
    "    submission['Category'] = predict\n",
    "    print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af9733d-8fa0-4663-ab5c-e69f25207166",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc057fd-fffd-4e02-8b83-91a53ffacfa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
