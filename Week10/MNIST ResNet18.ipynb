{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86ae24bf-8998-48f9-b20a-94ae2d702a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# cuda error 표시 안될 때 \n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d73a58c1-c23c-49e2-acb8-f32b0c4d9c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import sklearn\n",
    "import random\n",
    "import torchvision\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b0d0f0b-6a5f-4568-918a-2a435d9d557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting seed\n",
    "torch.manual_seed(1)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(1)\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db7a86fa-af38-4423-beb4-547125b2ec42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Columns: 785 entries, Category to 28x28\n",
      "dtypes: int64(785)\n",
      "memory usage: 359.3 MB\n",
      "None\n",
      "   Id  Category\n",
      "0   0         0\n",
      "1   1         0\n",
      "2   2         0\n",
      "3   3         0\n",
      "4   4         0\n",
      "   Category  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
      "0         5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "1         0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "2         3    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "3         3    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "4         6    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "\n",
      "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
      "0      0      0      0      0      0      0      0      0  \n",
      "1      0      0      0      0      0      0      0      0  \n",
      "2      0      0      0      0      0      0      0      0  \n",
      "3      0      0      0      0      0      0      0      0  \n",
      "4      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "# load data \n",
    "train = pd.read_csv(\"./2021-ai-w10-p1/train.csv\")\n",
    "test = pd.read_csv(\"./2021-ai-w10-p1/test.csv\")\n",
    "submission = pd.read_csv(\"./2021-ai-w10-p1/sample_submit.csv\")\n",
    "\n",
    "print(train.info())\n",
    "print(submission.head())\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbe8e132-ec38-40fb-b346-acac75ad1700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "\n",
    "# data scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "y_train = np.array(train['Category'])\n",
    "x_train = np.array(train.drop(['Category'],axis=1))\n",
    "x_test = np.array(test)\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acaf512a-c65f-42fe-a998-a820b29c294a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 784]) torch.Size([10000, 784])\n",
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "# set data on Tensor\n",
    "x_train = torch.Tensor(x_train).to(device)\n",
    "y_train = torch.LongTensor(y_train).to(device)\n",
    "x_test = torch.Tensor(x_test).to(device)\n",
    "\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cb33e60-98de-4174-8cd9-21efdf1ee051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 28, 28])\n",
      "torch.Size([10000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# chage data shape 1d -> 2d\n",
    "x_train = x_train.view(60000,1,28,28)\n",
    "x_test = x_test.view(10000,1,28,28)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d492a5ff-5ebb-4a89-8b58-51e50b1a09b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Tensor on Dataset\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff4bf528-360c-4bd1-ab3d-cbf6b93e3d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.conv1 = torch.nn.Conv2d(1,64,kernel_size = (7,7),stride =(2,2), padding=(3, 3), bias=True)\n",
    "model.fc = torch.nn.Linear(512,10,bias=True)\n",
    "\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dad4589-56f2-43bc-93f8-cdc6651b7d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting param, optim, cost function,dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "lr = 1e-3\n",
    "batch_size = 10\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "data_loader = DataLoader(dataset=train_dataset, batch_size = batch_size, shuffle=True)\n",
    "epochs = 20\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d5e4f09-b4d8-4b5f-b3a0-34cddd855696",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 메모리가 넘치게 됨 !! 왜???? 함수형 train 일때는 왜 정상작동 일까?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # learning\n",
    "# model.train()\n",
    "# for epoch in range(epochs+1):\n",
    "#     sum_cost = 0\n",
    "#     for x,y in data_loader:\n",
    "#         h = model(x)\n",
    "#         cost = loss(h,y)\n",
    "        \n",
    "#         optim.zero_grad()\n",
    "#         cost.backward()\n",
    "#         optim.step()\n",
    "#         sum_cost += cost\n",
    "#     if epoch % (epochs/10) == 0 :\n",
    "#         model.eval()\n",
    "#         predict = model(x_train)\n",
    "#         predict = torch.argmax(predict,dim=1)\n",
    "#         acc = predict == y_train\n",
    "#         acc = acc.float().mean().cpu().detach().item()\n",
    "#         print(epoch,sum_cost.item()/len(data_loader),acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42213f22-c923-465b-a271-83e1e1f336cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader):\n",
    "    model.train()\n",
    "    sum_cost = 0.0\n",
    "    sum_correct = 0\n",
    "    for data,target in data_loader:\n",
    "        optim.zero_grad()\n",
    "        output = model(data)\n",
    "        cost = loss(output,target)\n",
    "        sum_cost += cost.item()\n",
    "        predict = torch.argmax(output,dim=1)\n",
    "        correct = (predict == target).sum().item()\n",
    "        sum_correct += correct\n",
    "        cost.backward()\n",
    "        optim.step()\n",
    "    return sum_cost/len(data_loader.dataset),sum_correct/len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2110d7f0-687a-4061-b345-ced56c807f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.10211705977159242 66.805\n",
      "1 0.07623289671766882 76.06666666666668\n",
      "2 0.07090574819788648 78.26166666666666\n",
      "3 0.06802853074207281 79.24333333333334\n",
      "4 0.06612947376727436 79.87666666666667\n",
      "5 0.06486496378054532 80.25999999999999\n",
      "6 0.06390032868430329 80.58166666666666\n",
      "7 0.06262164665420229 81.06833333333333\n",
      "8 0.06233893939880654 81.31166666666667\n",
      "9 0.060255207381366443 81.77333333333333\n",
      "10 0.06043448791427848 81.67333333333333\n",
      "11 0.0595937585179694 82.31166666666667\n",
      "12 0.05911891209995374 82.21333333333334\n",
      "13 0.058747694427520036 82.405\n",
      "14 0.05820702289533025 82.46333333333334\n",
      "15 0.05875926433011579 82.40166666666666\n",
      "16 0.05799818872497417 82.80666666666666\n",
      "17 0.057781548094012154 82.77666666666667\n",
      "18 0.05772658939055982 82.75833333333334\n",
      "19 0.05731412079997826 82.77666666666667\n",
      "endtime = 3006.2206501960754\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "cur_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    cost,acc = train(model,data_loader)\n",
    "    print(epoch,cost,acc*100)\n",
    "print(\"endtime =\",time.time() - cur_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b37d2a3f-aa27-4039-acba-f65648c8a3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 0, 3,  ..., 9, 4, 5], device='cuda:0')\n",
      "tensor(0.8948, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    predict = model(x_train)\n",
    "    predict = torch.argmax(predict,dim=1)\n",
    "    print(predict)\n",
    "    acc = y_train == predict\n",
    "print(acc.float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0d84bdd-a0a9-4896-931f-2b8365b4941f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id  Category\n",
      "0        0         6\n",
      "1        1         1\n",
      "2        2         0\n",
      "3        3         0\n",
      "4        4         9\n",
      "...    ...       ...\n",
      "9995  9995         3\n",
      "9996  9996         7\n",
      "9997  9997         2\n",
      "9998  9998         8\n",
      "9999  9999         3\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    predict = model(x_test)\n",
    "    predict = torch.argmax(predict,dim=1)\n",
    "    submission['Category'] = predict.cpu().detach()\n",
    "    print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4af9733d-8fa0-4663-ab5c-e69f25207166",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc057fd-fffd-4e02-8b83-91a53ffacfa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
