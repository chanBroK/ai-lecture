{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-18T12:33:57.273574Z","iopub.execute_input":"2021-10-18T12:33:57.273936Z","iopub.status.idle":"2021-10-18T12:33:57.286245Z","shell.execute_reply.started":"2021-10-18T12:33:57.273884Z","shell.execute_reply":"2021-10-18T12:33:57.285256Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"import torch\nimport sklearn\nimport random\n# 장치 설정\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# 난수 시드 설정\ntorch.manual_seed(1)\nrandom.seed(1)\nif device == \"cuda\":\n    torch.cuda.manual_seed_all(1)\n    \n# 데이터 로드\ntrain = pd.read_csv(\"/kaggle/input/2021-ai-midterm-p5/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/2021-ai-midterm-p5/test.csv\")\nsubmission = pd.read_csv(\"/kaggle/input/2021-ai-midterm-p5/submit_sample.csv\")\n\n#데이터 확인\nprint(train.head())\nprint(test.head())\nprint(submission.head())\n\n# 데이터 전처리\n# 필요 없는 데이터 삭제 \n# InternetService와 [OlineSecurity ~ StreamingMovies] 까지 연관이 있다고 생각하여 해당 컬럼 삭제\ntrain = train.drop(['index','Unnamed: 0','customerID','OnlineSecurity','OnlineBackup',\n                    'DeviceProtection','TechSupport','StreamingTV','StreamingMovies'],axis=1)\ntest = test.drop(['index','Unnamed: 0','customerID','OnlineSecurity','OnlineBackup',\n                    'DeviceProtection','TechSupport','StreamingTV','StreamingMovies'],axis=1)\n\n\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder,MinMaxScaler\n\n\n# 난측값 채우기\n# from sklearn.impute import SimpleImputer\n# imputer = SimpleImputer(missing_values='?', strategy='most_frequent')\n# x_train = imputer.fit_transform(x_train)\n# x_test = imputer.transform(x_test)\n\n# data 실수화 \nle = LabelEncoder()\ntrain['Churn'] = le.fit_transform(train['Churn'])\n#gender 처리\ntrain['gender'] = le.fit_transform(train['gender'])\ntest['gender'] = le.transform(test['gender'])\n#Partner 처리\ntrain['Partner'] = le.fit_transform(train['Partner'])\ntest['Partner'] = le.transform(test['Partner'])\n#Dependents 처리\ntrain['Dependents'] = le.fit_transform(train['Dependents'])\ntest['Dependents'] = le.transform(test['Dependents'])\n#PhoneService 처리\ntrain['PhoneService'] = le.fit_transform(train['PhoneService'])\ntest['PhoneService'] = le.transform(test['PhoneService'])\n#MultipleLines 처리\ntrain['MultipleLines'] = le.fit_transform(train['MultipleLines'])\ntest['MultipleLines'] = le.transform(test['MultipleLines'])\n#InternetService 처리\ntrain['InternetService'] = le.fit_transform(train['InternetService'])\ntest['InternetService'] = le.transform(test['InternetService'])\n#Contract 처리\ntrain['Contract'] = le.fit_transform(train['Contract'])\ntest['Contract'] = le.transform(test['Contract'])\n\n\n\n#PaperlessBilling 처리\ntrain['PaperlessBilling'] = le.fit_transform(train['PaperlessBilling'])\ntest['PaperlessBilling'] = le.transform(test['PaperlessBilling'])\ntrain = train.drop(['PaperlessBilling'],axis=1)\ntest = test.drop(['PaperlessBilling'],axis=1)\n#PaymentMethod 처리\ntrain['PaymentMethod'] = le.fit_transform(train['PaymentMethod'])\ntest['PaymentMethod'] = le.transform(test['PaymentMethod'])\ntrain = train.drop(['PaymentMethod'],axis=1)\ntest = test.drop(['PaymentMethod'],axis=1)\n\n#TotalCharge 처리\n# train['TotalCharges'] = train['TotalCharges'].astype(float)\n# test['TotalCharges'] = test['TotalCharges'].astype(float)\ntrain = train.drop(['TotalCharges'],axis=1)\ntest = test.drop(['TotalCharges'],axis=1)\n# 배열로 변환\n\nx_train = np.array(train.drop(['Churn'],axis=1))\ny_train = np.array(train['Churn'])\nx_test = np.array(test)\n\n#데이터 확인\nprint(train.head())\nprint(test.head())\nprint(x_train)\n\n# 데이터 변형(scale)\nscaler = StandardScaler()\n# scaler = MinMaxScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)\n\n\n\n# 데이터 텐서에 올리기\nx_train = torch.Tensor(x_train).to(device)\nx_test = torch.Tensor(x_test).to(device)\ny_train = torch.Tensor(y_train).to(device)\n\n# 데이터 셋 \nfrom torch.utils.data import DataLoader,TensorDataset\ntrain_dataset = TensorDataset(x_train,y_train)\n\n# 데이터 모양 확인\nprint(x_train.shape , y_train.shape)\n\n# Layer 설정\nlayer1 = torch.nn.Linear(10,64,bias =True).to(device)\nlayer2 = torch.nn.Linear(64,10,bias =True).to(device)\nlayer3 = torch.nn.Linear(10,1,bias =True).to(device)\nrelu = torch.nn.ReLU().to(device)\ndropout = torch.nn.Dropout(0.3).to(device)\n\n# Layer 초기화\ntorch.nn.init.xavier_normal_(layer1.weight)\ntorch.nn.init.xavier_normal_(layer2.weight)\ntorch.nn.init.xavier_normal_(layer3.weight)\n\n\n# Model 설정\nmodel = torch.nn.Sequential(layer1,relu,dropout,\n                            layer2,relu,dropout,\n                            layer3).to(device)\n\n# 학습 파라미터 설정\nepochs = 1000\nlr = 0.01\nbatch_size = 100\n\n# loss 함수 이진 분류\n# loss = torch.nn.CrossEntropyLoss()\n# loss = torch.nn.MSELoss()\nloss =torch.nn.BCELoss()\n\n# optim \noptim = torch.optim.Adam(model.parameters(),lr=lr)\n\n#data loader\ndata_loader = DataLoader(dataset=train_dataset,batch_size=batch_size)\n\n# 학습\nmodel.train()\nfor epoch in range(epochs):\n    optim.zero_grad()\n    h = model(x_train)\n    cost = loss(torch.sigmoid(h),y_train.unsqueeze(1))\n    cost.backward()\n    optim.step()\n    if epoch % 100 == 0:\n        print(epoch , cost.item())","metadata":{"execution":{"iopub.status.busy":"2021-10-18T12:33:57.288748Z","iopub.execute_input":"2021-10-18T12:33:57.289083Z","iopub.status.idle":"2021-10-18T12:33:59.858057Z","shell.execute_reply.started":"2021-10-18T12:33:57.289050Z","shell.execute_reply":"2021-10-18T12:33:59.857185Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    model.eval()\n    predict = torch.sigmoid(model(x_test))\npredict = predict >= torch.Tensor([0.5]).to(device)\nsubmission['Churn'] = predict.int()\nsubmission.to_csv(\"submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T12:33:59.859342Z","iopub.execute_input":"2021-10-18T12:33:59.859575Z","iopub.status.idle":"2021-10-18T12:33:59.871406Z","shell.execute_reply.started":"2021-10-18T12:33:59.859548Z","shell.execute_reply":"2021-10-18T12:33:59.870431Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}