{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. DataFrame.info()와 DataFrame.describe()를 통해 데이터 확인 (데이터 타입이 Object면 이상감지)\n",
    "# 2. np.unique(array) 를 통해서 중복제거된 값 확인\n",
    "# 3. 잘못들어간 값에 대해서 imputer를 이용해 최근 빈도로 넣게 되면 잘못된 학습이 될 가능성이 있음!\n",
    "# 4. 최근 빈도 대신 상수값을 넣어 처리해도 된다. \n",
    "# 5. astype을 이용하여 문자열로 된 숫자 데이터를 실수형으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 시드 설정\n",
    "torch.manual_seed(1)\n",
    "if device == \"cuda\" :\n",
    "    torch.cuda.manual_seed_all(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index  age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  \\\n",
      "0        0   63    1   1       145   233    1        2      150      0   \n",
      "1        1   67    1   4       160   286    0        2      108      1   \n",
      "2        2   67    1   4       120   229    0        2      129      1   \n",
      "3        4   41    0   2       130   204    0        2      172      0   \n",
      "4        5   56    1   2       120   236    0        0      178      0   \n",
      "..     ...  ...  ...  ..       ...   ...  ...      ...      ...    ...   \n",
      "237    295   41    1   2       120   157    0        0      182      0   \n",
      "238    296   59    1   4       164   176    1        2       90      0   \n",
      "239    299   68    1   4       144   193    1        0      141      0   \n",
      "240    300   57    1   4       130   131    0        0      115      1   \n",
      "241    301   57    0   2       130   236    0        2      174      0   \n",
      "\n",
      "     oldpeak  slope ca thal  target  \n",
      "0        2.3      3  0    6       0  \n",
      "1        1.5      2  3    3       2  \n",
      "2        2.6      2  2    7       1  \n",
      "3        1.4      1  0    3       0  \n",
      "4        0.8      1  0    3       0  \n",
      "..       ...    ... ..  ...     ...  \n",
      "237      0.0      1  0    3       0  \n",
      "238      1.0      2  2    6       3  \n",
      "239      3.4      2  2    7       2  \n",
      "240      1.2      2  1    7       3  \n",
      "241      0.0      2  1    3       1  \n",
      "\n",
      "[242 rows x 15 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 242 entries, 0 to 241\n",
      "Data columns (total 15 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   index     242 non-null    int64  \n",
      " 1   age       242 non-null    int64  \n",
      " 2   sex       242 non-null    int64  \n",
      " 3   cp        242 non-null    int64  \n",
      " 4   trestbps  242 non-null    int64  \n",
      " 5   chol      242 non-null    int64  \n",
      " 6   fbs       242 non-null    int64  \n",
      " 7   restecg   242 non-null    int64  \n",
      " 8   thalach   242 non-null    int64  \n",
      " 9   exang     242 non-null    int64  \n",
      " 10  oldpeak   242 non-null    float64\n",
      " 11  slope     242 non-null    int64  \n",
      " 12  ca        242 non-null    object \n",
      " 13  thal      242 non-null    object \n",
      " 14  target    242 non-null    int64  \n",
      "dtypes: float64(1), int64(12), object(2)\n",
      "memory usage: 28.5+ KB\n",
      "None\n",
      "            index         age         sex          cp    trestbps        chol  \\\n",
      "count  242.000000  242.000000  242.000000  242.000000  242.000000  242.000000   \n",
      "mean   146.818182   54.582645    0.681818    3.152893  131.690083  248.805785   \n",
      "std     86.364229    9.124507    0.466736    0.966971   17.972057   54.512014   \n",
      "min      0.000000   29.000000    0.000000    1.000000   94.000000  126.000000   \n",
      "25%     72.250000   48.000000    0.000000    2.250000  120.000000  211.000000   \n",
      "50%    145.500000   56.000000    1.000000    3.000000  130.000000  244.000000   \n",
      "75%    220.750000   61.000000    1.000000    4.000000  140.000000  277.750000   \n",
      "max    301.000000   77.000000    1.000000    4.000000  200.000000  564.000000   \n",
      "\n",
      "             fbs     restecg     thalach       exang     oldpeak       slope  \\\n",
      "count  242.00000  242.000000  242.000000  242.000000  242.000000  242.000000   \n",
      "mean     0.14876    0.979339  150.033058    0.326446    1.054545    1.595041   \n",
      "std      0.35659    0.995627   22.690387    0.469885    1.173108    0.618907   \n",
      "min      0.00000    0.000000   71.000000    0.000000    0.000000    1.000000   \n",
      "25%      0.00000    0.000000  137.250000    0.000000    0.000000    1.000000   \n",
      "50%      0.00000    0.000000  153.000000    0.000000    0.800000    2.000000   \n",
      "75%      0.00000    2.000000  166.750000    1.000000    1.600000    2.000000   \n",
      "max      1.00000    2.000000  202.000000    1.000000    6.200000    3.000000   \n",
      "\n",
      "           target  \n",
      "count  242.000000  \n",
      "mean     0.933884  \n",
      "std      1.223800  \n",
      "min      0.000000  \n",
      "25%      0.000000  \n",
      "50%      0.000000  \n",
      "75%      2.000000  \n",
      "max      4.000000  \n"
     ]
    }
   ],
   "source": [
    "# csv 데이터 로드\n",
    "train = pd.read_csv(\"2021-ai-midterm-p3/train.csv\")\n",
    "test = pd.read_csv(\"2021-ai-midterm-p3/test.csv\")\n",
    "submission = pd.read_csv(\"2021-ai-midterm-p3/submit_sample.csv\")\n",
    "\n",
    "# 데이터 확인\n",
    "print(train)\n",
    "print(train.info())\n",
    "print(train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3  6  7  ?\n",
      "0    0  1  0  0\n",
      "1    1  0  0  0\n",
      "2    0  0  1  0\n",
      "3    1  0  0  0\n",
      "4    1  0  0  0\n",
      "..  .. .. .. ..\n",
      "237  1  0  0  0\n",
      "238  0  1  0  0\n",
      "239  0  0  1  0\n",
      "240  0  0  1  0\n",
      "241  1  0  0  0\n",
      "\n",
      "[242 rows x 4 columns]\n",
      "     0  1  2  3  ?\n",
      "0    1  0  0  0  0\n",
      "1    0  0  0  1  0\n",
      "2    0  0  1  0  0\n",
      "3    1  0  0  0  0\n",
      "4    1  0  0  0  0\n",
      "..  .. .. .. .. ..\n",
      "237  1  0  0  0  0\n",
      "238  0  0  1  0  0\n",
      "239  0  0  1  0  0\n",
      "240  0  1  0  0  0\n",
      "241  0  1  0  0  0\n",
      "\n",
      "[242 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding을 통해 ca,thal에 ?란 값이 있음을 확인\n",
    "print(pd.get_dummies(train['thal']))\n",
    "print(pd.get_dummies(train['ca']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "\n",
    "# Object 타입인 ca, thal 컬럼의 전처리(결측값 = ?)\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# imputer = SimpleImputer(missing_values=\"?\",strategy=\"most_frequent\")\n",
    "# x_train = imputer.fit_transform(x_train)\n",
    "# x_test = imputer.transform(x_test)\n",
    "\n",
    "# # thal 처리\n",
    "# train = pd.concat([train,pd.get_dummies(train['thal']).drop(['?'],axis=1)],axis=1)\n",
    "# # ca 에서도 3 이라는 컬럼이 생성되므로 컬럼명 교체\n",
    "# train['3t'] = train['3']\n",
    "# train = train.drop(['3'],axis=1)\n",
    "# # ca 처리\n",
    "# train = pd.concat([train,pd.get_dummies(train['ca']).drop(['?'],axis=1)],axis=1)\n",
    "\n",
    "# # thal 처리\n",
    "# test = pd.concat([test,pd.get_dummies(test['thal']).drop(['?'],axis=1)],axis=1)\n",
    "# # ca 에서도 3 이라는 컬럼이 생성되므로 컬럼명 교체\n",
    "# test['3t'] = test['3']\n",
    "# test = test.drop(['3'],axis=1)\n",
    "# # ca 처리\n",
    "# test = pd.concat([test,pd.get_dummies(test['ca']).drop(['?'],axis=1)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용하지 않은 컬럼을 제거하여 Train, Test 데이터 설정\n",
    "# x_train = np.array(train.drop([\"index\",\"target\",\"thal\",\"ca\"],axis=1))\n",
    "# x_test = np.array(test.drop([\"index\",\"thal\",\"ca\"],axis=1))\n",
    "# y_train = np.array(train[\"target\"])\n",
    "x_train = np.array(train.drop([\"index\",\"target\"],axis=1))\n",
    "x_test = np.array(test.drop([\"index\"],axis=1))\n",
    "y_train = np.array(train[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "# 값의 범위가 크므로 정규화가 필요\n",
    "\n",
    "# Object 타입인 ca, thal 컬럼의 전처리(결측값 = ?)\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=\"?\",strategy=\"constant\",fill_value=int(8))\n",
    "x_train = imputer.fit_transform(x_train)\n",
    "x_test = imputer.transform(x_test)\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# x_train = scaler.fit_transform(x_train)\n",
    "# x_test = scaler.transform(x_test)\n",
    "\n",
    "x_train = x_train.astype(float)\n",
    "x_test = x_test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 분류 값 확인\n",
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242, 13)\n",
      "(242,)\n",
      "(61, 13)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 모양 확인\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 Tensor에 올리기\n",
    "x_train = torch.Tensor(x_train).to(device)\n",
    "x_test = torch.Tensor(x_test).to(device)\n",
    "y_train = torch.LongTensor(y_train).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이어 생성\n",
    "layer1 = torch.nn.Linear(x_train.shape[1],64,bias=True).to(device)\n",
    "layer2 = torch.nn.Linear(64,64,bias=True).to(device)\n",
    "layer3 = torch.nn.Linear(64,64,bias=True).to(device)\n",
    "layer4 = torch.nn.Linear(64,5,bias=True).to(device)\n",
    "relu = torch.nn.ReLU().to(device)\n",
    "dropout = torch.nn.Dropout(0.2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 레이어 가중치 초기화\n",
    "# torch.nn.init.xavier_normal_(layer1.weight)\n",
    "# torch.nn.init.xavier_normal_(layer2.weight)\n",
    "# torch.nn.init.xavier_normal_(layer3.weight)\n",
    "# torch.nn.init.xavier_normal_(layer4.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = torch.nn.Sequential(layer1, relu,\n",
    "                           layer2, relu,\n",
    "                           layer3, relu,\n",
    "                           layer4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 파라미터 설정\n",
    "lr = 1e-3\n",
    "epochs = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수, 최적화 함수 정의\n",
    "loss = torch.nn.CrossEntropyLoss().to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.8719284534454346 0.05371900647878647\n",
      "70 1.0628666877746582 0.5909090638160706\n",
      "140 0.9015001654624939 0.6694214344024658\n",
      "210 0.7570487260818481 0.6859503984451294\n",
      "280 0.6831952333450317 0.7231404781341553\n",
      "350 0.6244838237762451 0.7438015937805176\n",
      "420 0.5651431083679199 0.7644627690315247\n",
      "490 0.5031994581222534 0.8016528487205505\n",
      "560 0.4547404646873474 0.8305785059928894\n",
      "630 0.4059681296348572 0.85537189245224\n",
      "700 0.359203577041626 0.8760330080986023\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "model.train()\n",
    "for epoch in range(epochs+1):\n",
    "    optim.zero_grad()\n",
    "    h = model(x_train)\n",
    "    cost = loss(h,y_train)\n",
    "    cost.backward()\n",
    "    optim.step()\n",
    "    if epoch % (epochs/10) == 0:\n",
    "        predict = torch.argmax(h,dim=1)\n",
    "        acc = sum(predict == y_train) / len(y_train)\n",
    "        print(epoch, cost.item(),acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index  target\n",
      "0       3       0\n",
      "1       6       1\n",
      "2      21       0\n",
      "3      24       1\n",
      "4      31       1\n",
      "..    ...     ...\n",
      "56    293       1\n",
      "57    294       0\n",
      "58    297       0\n",
      "59    298       1\n",
      "60    302       1\n",
      "\n",
      "[61 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    predict = model(x_test)\n",
    "    predict = torch.argmax(predict,dim=1)\n",
    "    predict = predict.cpu().detach().numpy()\n",
    "    predict = predict != 0\n",
    "    predict = predict.astype(int)\n",
    "submission[\"target\"] = predict\n",
    "print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
