{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "torch.manual_seed(1)\n",
    "random.seed(1)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class to use data_loader(batch_size)\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x = torch.Tensor(x).to(device)\n",
    "        self.y = torch.LongTensor(y).to(device)\n",
    "        self.len = len(x)\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load\n",
    "train = pd.read_csv(\"./data1/mnist_train.csv\")\n",
    "test = pd.read_csv(\"./data1/mnist_test.csv\")\n",
    "submission = pd.read_csv(\"./data1/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0    0    1    2    3    4    5    6    7    8  ...  775  776  \\\n",
      "0           0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "1           1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "2           2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "3           3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "4           4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "\n",
      "   777  778  779  780  781  782  783  784  \n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  5.0  \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  9.0  \n",
      "\n",
      "[5 rows x 786 columns]\n",
      "   Unnamed: 0    0    1    2    3    4    5    6    7    8  ...  774  775  \\\n",
      "0           0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "1           1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "2           2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "3           3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "4           4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "\n",
      "   776  777  778  779  780  781  782  783  \n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 785 columns]\n",
      "   id  Label\n",
      "0   0      7\n",
      "1   1      2\n",
      "2   2      1\n",
      "3   3      0\n",
      "4   4      9\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "# check data\n",
    "print(train.head())\n",
    "print(test.head())\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing and set x_train, y_train ,x_test\n",
    "x_train = np.array(train.drop(['0','784'],axis=1))\n",
    "y_train = np.array(train['784']).astype(int)\n",
    "x_test = np.array(test.drop(['0'],axis=1))\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "\n",
    "# x_train = torch.Tensor(x_train).to(device)\n",
    "# y_train = torch.LongTensor(y_train).to(device)\n",
    "x_test = torch.Tensor(x_test).to(device)\n",
    "# print(x_train.shape)\n",
    "# print(y_train.shape)\n",
    "train_dataset= TrainDataset(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set layer\n",
    "layer1 = torch.nn.Linear(784,784,bias=True).to(device)\n",
    "layer2 = torch.nn.Linear(784,512,bias=True).to(device)\n",
    "layer3 = torch.nn.Linear(512,512,bias=True).to(device)\n",
    "layer4 = torch.nn.Linear(512,512,bias=True).to(device)\n",
    "# layer5 = torch.nn.Linear(512,512,bias=True).to(device)\n",
    "# layer6 = torch.nn.Linear(512,512,bias=True).to(device)\n",
    "layer5 = torch.nn.Linear(512,len(le.classes_),bias=True).to(device)\n",
    "\n",
    "relu = torch.nn.ReLU().to(device)\n",
    "dropout = torch.nn.Dropout(0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0428,  0.0986, -0.0521,  ..., -0.1125,  0.0049,  0.0007],\n",
       "        [-0.0517,  0.0146, -0.0199,  ...,  0.0611, -0.0283, -0.0044],\n",
       "        [-0.0786,  0.0395,  0.0706,  ..., -0.1171, -0.1067, -0.0755],\n",
       "        ...,\n",
       "        [ 0.0520,  0.0433,  0.0006,  ...,  0.0198,  0.0292,  0.0357],\n",
       "        [ 0.0593, -0.1006,  0.0465,  ...,  0.0177,  0.0913, -0.0426],\n",
       "        [-0.1846, -0.0373, -0.0379,  ...,  0.0046, -0.0413, -0.0390]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init layers\n",
    "torch.nn.init.xavier_normal_(layer1.weight)\n",
    "torch.nn.init.xavier_normal_(layer2.weight)\n",
    "torch.nn.init.xavier_normal_(layer3.weight)\n",
    "torch.nn.init.xavier_normal_(layer4.weight)\n",
    "torch.nn.init.xavier_normal_(layer5.weight)\n",
    "# torch.nn.init.xavier_normal_(layer6.weight)\n",
    "# torch.nn.init.xavier_normal_(layer7.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model\n",
    "model = torch.nn.Sequential(layer1,relu,dropout,\n",
    "                            layer2,relu,dropout,\n",
    "                            layer3,relu,dropout,\n",
    "                            layer4,relu,dropout,\n",
    "                            # layer5,relu,dropout,\n",
    "                            # layer6,relu,dropout,\n",
    "                            layer5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Learning params and function\n",
    "# 목표 !! cost 0.04 정도 \n",
    "# layer 5\n",
    "# epochs 15 , batch_size 100 -> cost 0.4/// 0.9566\n",
    "# epochs 50, batch_size 600 -> cost 0.17// 0.9706\n",
    "# epochs 100, batch_size 600 -> cost 0.073// -> overfitting? 0.9796\n",
    "# epochs 100, batch_size 1000 -> cost 0.094 // 0.9785\n",
    "# epochs 100, batch_size 500 -> cost  0.067 // 0.9797\n",
    "# epochs 100, batch_size 300 -> cost  0.114676796 // 0.9782\n",
    "# 실습 7번 세팅대로 -> cost 0.24 // 0.96\n",
    "# layer 5->7, epochs 100, batch_size 500 ->  cost 0.08// 0.9657\n",
    "# layer 5->7, epochs 150, batch_size 500 ->  cost 0.08// 0.9657\n",
    "\n",
    "## 정답 csv를 다운 받아서 로컬에서 모델 평가를 해보자 \n",
    "epochs = 150\n",
    "lr = 0.001\n",
    "batch_size = 500\n",
    "optim = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "loss = torch.nn.CrossEntropyLoss().to(device)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle = True,\n",
    "                                         drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 00 || cost = 135.666061401\n",
      "epoch = 01 || cost = 2.308957100\n",
      "epoch = 02 || cost = 2.276726484\n",
      "epoch = 03 || cost = 2.203403950\n",
      "epoch = 04 || cost = 1.993398905\n",
      "epoch = 05 || cost = 1.626382709\n",
      "epoch = 06 || cost = 1.435201287\n",
      "epoch = 07 || cost = 1.376437545\n",
      "epoch = 08 || cost = 1.322339773\n",
      "epoch = 09 || cost = 1.287824035\n",
      "epoch = 10 || cost = 1.242817402\n",
      "epoch = 11 || cost = 1.249763131\n",
      "epoch = 12 || cost = 1.215005159\n",
      "epoch = 13 || cost = 1.226069450\n",
      "epoch = 14 || cost = 1.231827617\n",
      "epoch = 15 || cost = 1.220015645\n"
     ]
    }
   ],
   "source": [
    "# learning\n",
    "model.train()\n",
    "batch_num = len(data_loader)\n",
    "for epoch in range(epochs+1):\n",
    "    avg_cost = 0\n",
    "    for x,y in data_loader:\n",
    "        optim.zero_grad()\n",
    "        h = model(x)\n",
    "        cost = loss(h,y)\n",
    "        cost.backward()\n",
    "        optim.step()\n",
    "        avg_cost += cost\n",
    "\n",
    "    print(\"epoch = {:02d} || cost = {:.9f}\".format(epoch,avg_cost/batch_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.778750\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    predict = model(train_dataset.x)\n",
    "predict = torch.softmax(predict,dim = 1)\n",
    "predict = torch.argmax(predict,dim = 1)\n",
    "# print(predict)\n",
    "# print(dataset.y)\n",
    "accuracy = (predict == train_dataset.y).float().mean()\n",
    "print(\"Accuracy = {:f}\".format(accuracy.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  Label\n",
      "0        0      7\n",
      "1        1      2\n",
      "2        2      1\n",
      "3        3      0\n",
      "4        4      9\n",
      "...    ...    ...\n",
      "9995  9995      2\n",
      "9996  9996      3\n",
      "9997  9997      4\n",
      "9998  9998      8\n",
      "9999  9999      6\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# submission\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    predict = model(x_test)\n",
    "predict = torch.softmax(predict,dim=1)\n",
    "predict = torch.argmax(predict,dim=1)\n",
    "predict = le.inverse_transform(predict.cpu().detach().numpy())\n",
    "submission['Label'] = predict\n",
    "print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\",index=False)\n",
    "# 왜 학습 이후에 계속 한가지 정수로만 결과가 나올까?(batch_size 적용 X)\n",
    "# batch size가 없으면 한가지 정수로만 예측 결과가 나온다. -> batch size 적용이 필요 \n",
    "# batch size를 반복문으로 구현하여도 제대로된 예측 결과가 나오지 않음\n",
    "# Dataloader를 통해 batch size를 사용해야함 \n",
    "# Data loader 사용을 위해 Dataset Class 의 인스턴스가 필요함 \n",
    "# CSV 파일에서 읽어온 데이터를 Dataset Class로 만들기 위해 Dataset을 상속받은 클래스 생성\n",
    "# 생성자, __len__, __getitem__ 함수 구현해야함 \n",
    "\n",
    "\n",
    "### 위의 추론은 틀렸다. \n",
    "# batch_size = 600 기준 , 신경망의 개수가 5개보다 많아지면 Gradient Vanishing이 발생하는 것 같다.\n",
    "# 6개 부터는 위와 같이 한가지 정수로만 예측결과를 얻게 된다.\n",
    "# 우선!!제대로된 batch_size의 적용을 위해 Dataset 클래스를 상속하는 커스텀 클래스를 생성해야함!!\n",
    "# + learning late 조정 와 batch_size 조정 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
