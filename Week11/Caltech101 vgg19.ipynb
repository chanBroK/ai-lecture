{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f5e0c96-41d9-4e9d-9285-e04a88536c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# cuda error 표시 안될 때 \n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb2b7357-27f0-4121-855c-da47ae6e1704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sklearn\n",
    "import torchvision\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9369e3e6-249b-4e0d-97cd-a8606f91a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# set seed\n",
    "torch.manual_seed(1)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20f890e4-9919-4781-b4b5-d19442eeffa8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0              1\n",
      "0      1          Faces\n",
      "1      2     Faces_easy\n",
      "2      3       Leopards\n",
      "3      4     Motorbikes\n",
      "4      5      accordion\n",
      "..   ...            ...\n",
      "96    97     wheelchair\n",
      "97    98       wild_cat\n",
      "98    99  windsor_chair\n",
      "99   100         wrench\n",
      "100  101       yin_yang\n",
      "\n",
      "[101 rows x 2 columns]\n",
      "                 Id  Category\n",
      "0     img_00000.csv        42\n",
      "1     img_00001.csv        42\n",
      "2     img_00002.csv        42\n",
      "3     img_00003.csv        42\n",
      "4     img_00004.csv        42\n",
      "...             ...       ...\n",
      "1707  img_01707.csv        42\n",
      "1708  img_01708.csv        42\n",
      "1709  img_01709.csv        42\n",
      "1710  img_01710.csv        42\n",
      "1711  img_01711.csv        42\n",
      "\n",
      "[1712 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# csv load\n",
    "import os\n",
    "data_path = \"./2021-ai-w11-p1/\"\n",
    "labelname_csv_path = os.path.join(data_path,\"Label2Names.csv\")\n",
    "labelname = pd.read_csv(labelname_csv_path,header=None)\n",
    "print(labelname)\n",
    "train_dir_path = os.path.join(data_path,\"train_csv_v2\")\n",
    "test_dir_path = os.path.join(data_path,\"test_csv_v2\")\n",
    "submission = pd.read_csv(os.path.join(data_path,\"submission.csv\"))\n",
    "print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f1c8cb8-ac6a-4577-a9c0-99e33724b78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(dir_path,labelname):\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    for dir_name in tqdm(os.listdir(dir_path)):\n",
    "        # dirname to label\n",
    "        if dir_name == \"BACKGROUND_Google\":\n",
    "            continue\n",
    "        else:\n",
    "            label = labelname.index[labelname[1] == dir_name].tolist()[0] + 1\n",
    "            for csv_name in os.listdir(os.path.join(dir_path,dir_name)):\n",
    "                csv_path = os.path.join(dir_path,dir_name,csv_name)\n",
    "                # reshape 1d to 2d\n",
    "                train_x.append(np.array(pd.read_csv(csv_path)).reshape((256,256,3)).transpose((2,0,1)))\n",
    "                train_y.append(label)\n",
    "    return train_x,train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ee8ee08-7866-4410-89c0-6a8cc4530e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 102/102 [00:53<00:00,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3030 3030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load train_x,train_y\n",
    "train_x, train_y = load_train_data(train_dir_path,labelname)\n",
    "print(len(train_x),len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11abc1a0-7429-48cb-9444-187917efb0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data scaling\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# train_x = np.array(train_x)\n",
    "# train_y = np.array(train_y)\n",
    "# test_x = np.array(test_x)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# train_x = scaler.fit_transform(train_x)\n",
    "# test_x = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "979b4b6d-118f-4f0c-9b00-40fe6b63ad8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3030, 3, 256, 256)\n",
      "(3030,)\n"
     ]
    }
   ],
   "source": [
    "# data reshape 1D -> 2D(3channel)\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "# train_x = train_x.reshape((len(train_x),256,256,3))\n",
    "# train_x = train_x.transpose(0,3,1,2)\n",
    "# test_x = test_x.reshape((len(test_x),256,256,3))\n",
    "# test_x = test_x.transpose(0,3,1,2)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65db4e1d-a4fc-4111-a76e-752de56d82d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data to tensor , dataset\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "train_dataset = TensorDataset(torch.FloatTensor(train_x),torch.LongTensor(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f87d4ded-47ea-4e8d-9dbd-c2038a3f30d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory clear\n",
    "del train_x\n",
    "del train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eff06a3f-b359-4691-ad01-c014e910aa8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): ReLU(inplace=True)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (33): ReLU(inplace=True)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=101, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model load\n",
    "model = torchvision.models.vgg19(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False    \n",
    "model.classifier[6] = torch.nn.Linear(in_features=4096, out_features=101, bias=True)\n",
    "# init xavier\n",
    "torch.nn.init.xavier_normal_(model.classifier[0].weight)\n",
    "torch.nn.init.xavier_normal_(model.classifier[3].weight)\n",
    "torch.nn.init.xavier_normal_(model.classifier[6].weight)\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a4fd0f1-5717-41cf-867b-09aa4049bb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting param, optim, cost function,dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "lr = 1e-3\n",
    "batch_size = 16\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "train_data_loader = DataLoader(dataset=train_dataset, batch_size = batch_size, shuffle=True)\n",
    "epochs = 100\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c8ff5a7-fa7c-4447-ab08-7c4539dfebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader):\n",
    "    model.train()\n",
    "    sum_cost = 0.0\n",
    "    sum_correct = 0\n",
    "    for i,data in enumerate(data_loader):\n",
    "        data, target = data[0].to(device),data[1].to(device)\n",
    "        optim.zero_grad()\n",
    "        output = model(data)\n",
    "        cost = loss(output,target - 1)\n",
    "        predict = torch.argmax(output,dim=1)\n",
    "        correct = (predict == target - 1).sum().item()\n",
    "        sum_cost += cost.item()\n",
    "        sum_correct += correct\n",
    "        cost.backward()\n",
    "        optim.step()\n",
    "    return sum_cost/len(data_loader.dataset),sum_correct/len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe49907b-1ed8-4126-8560-00ea2cf93ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.6775129802943063 4.818481848184819\n",
      "1 2.4356997002076 18.05280528052805\n",
      "2 1.8269342723065871 30.363036303630363\n",
      "3 1.6241819150377028 36.36963696369637\n",
      "4 1.4782854860765313 41.584158415841586\n",
      "5 1.3654292005910338 46.73267326732674\n",
      "6 1.2098446888498742 48.81188118811881\n",
      "7 1.1537900679182298 52.508250825082506\n",
      "8 1.163209024199558 53.72937293729373\n",
      "9 1.0370983581731814 57.42574257425742\n",
      "10 1.0125021919755652 58.84488448844885\n",
      "11 1.0052616168956945 60.26402640264027\n",
      "12 0.958423920865893 61.18811881188119\n",
      "13 0.8999222030328347 63.26732673267327\n",
      "14 0.955591065498075 61.84818481848184\n",
      "15 1.0178436714282917 62.44224422442244\n",
      "16 0.9260187205308341 64.52145214521452\n",
      "17 0.9098925588154557 65.77557755775577\n",
      "18 0.8933283790571018 66.36963696369637\n",
      "19 0.8989799737930297 66.006600660066\n",
      "20 0.8278325998350339 68.61386138613862\n",
      "21 0.847393749614489 68.48184818481849\n",
      "22 0.8900543831362583 67.35973597359735\n",
      "23 0.89236364593797 67.22772277227723\n",
      "24 0.896262023457585 69.17491749174917\n",
      "25 0.9203827338446878 68.87788778877888\n",
      "26 0.8368557454982491 70.26402640264027\n",
      "27 0.7736376870875001 72.54125412541255\n",
      "28 0.8203055643995997 71.71617161716172\n",
      "29 0.8630485802692155 72.01320132013201\n",
      "30 0.8142954121943158 72.27722772277228\n",
      "31 0.7912247161537704 71.32013201320132\n",
      "32 0.853633424926461 72.34323432343234\n",
      "33 0.8070361401221835 73.72937293729372\n",
      "34 0.8256089523188745 73.06930693069307\n",
      "35 0.8417151011551174 72.50825082508251\n",
      "36 0.7956468930731454 73.86138613861387\n",
      "37 0.8415825676209856 73.72937293729372\n",
      "38 0.7531929026973453 75.67656765676568\n",
      "39 0.8143454182856154 73.993399339934\n",
      "40 0.8219008348980555 74.0924092409241\n",
      "41 0.8449562428414625 73.43234323432343\n",
      "42 0.8386357298778622 74.91749174917491\n",
      "43 0.7859084688373991 75.28052805280528\n",
      "44 0.7729959880703985 74.81848184818482\n",
      "45 0.7756505688448978 76.66666666666667\n",
      "46 0.780096487401461 75.74257425742574\n",
      "47 0.804749383420834 76.56765676567657\n",
      "48 0.706475060175518 77.59075907590758\n",
      "49 0.8106061136818195 76.43564356435644\n",
      "50 0.7741711449972277 77.35973597359735\n",
      "51 0.791718973007465 77.98679867986799\n",
      "52 0.7905859755671777 78.54785478547855\n",
      "53 0.8041974565672009 77.16171617161716\n",
      "54 0.7188357428109685 78.51485148514851\n",
      "55 0.8255878906238986 76.73267326732673\n",
      "56 0.7930112029950362 77.85478547854785\n",
      "57 0.8985557956435997 76.07260726072607\n",
      "58 0.6869440561698986 79.66996699669967\n",
      "59 0.7296874867079434 78.91089108910892\n",
      "60 0.7559347600875908 78.44884488448844\n",
      "61 0.7705662819184977 77.95379537953795\n",
      "62 0.7236612555378604 79.73597359735973\n",
      "63 0.7222165943101867 79.83498349834983\n",
      "64 0.739087544518608 79.43894389438944\n",
      "65 0.7769639760739802 79.8019801980198\n",
      "66 0.7542791770530631 78.87788778877888\n",
      "67 0.7293577275010732 79.93399339933993\n",
      "68 0.741871305520057 79.10891089108911\n",
      "69 0.8251625034106292 79.33993399339934\n",
      "70 0.801102267236958 79.86798679867987\n",
      "71 0.7759818025366667 78.61386138613862\n",
      "72 0.7041312483454868 80.2970297029703\n",
      "73 0.7765000155494476 79.63696369636963\n",
      "74 0.7356523609980887 80.3960396039604\n",
      "75 0.7326796062113357 81.22112211221122\n",
      "76 0.7527631365883427 80.2970297029703\n",
      "77 0.6836391086833246 81.51815181518151\n",
      "78 0.8246985467785012 80.03300330033002\n",
      "79 0.7328941057251218 81.15511551155116\n",
      "80 0.6805773862729261 81.74917491749176\n",
      "81 0.7789002409005293 80.92409240924093\n",
      "82 0.7977351032848516 80.0\n",
      "83 0.8209752981783149 80.23102310231023\n",
      "84 0.7385656181811869 80.42904290429043\n",
      "85 0.7987904932611951 80.42904290429043\n",
      "86 0.7510006854162129 80.6930693069307\n",
      "87 0.750841035840181 81.22112211221122\n",
      "88 0.7489516782866354 81.28712871287128\n",
      "89 0.7263212899184324 82.50825082508251\n",
      "90 0.7155753228598445 81.02310231023102\n",
      "91 0.8173202956524097 81.0891089108911\n",
      "92 0.7042924822718286 82.70627062706271\n",
      "93 0.7579206571394583 81.25412541254126\n",
      "94 0.7245927917340279 81.71617161716172\n",
      "95 0.7282266171944471 81.55115511551155\n",
      "96 0.7715795304835165 81.61716171617161\n",
      "97 0.7526713425651648 81.32013201320132\n",
      "98 0.8082605645046966 81.51815181518151\n",
      "99 0.7077720160758916 82.54125412541255\n",
      "endtime = 762.3582847118378\n"
     ]
    }
   ],
   "source": [
    "#train \n",
    "import time\n",
    "cur_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    cost,acc = train(model,train_data_loader)\n",
    "    print(epoch,cost,acc * 100)\n",
    "print(\"endtime =\",time.time() - cur_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fe206c4-c0bd-4ab7-a9a4-10bd4bc83e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data_loader):\n",
    "    model.eval()\n",
    "    sum_correct = 0\n",
    "    for i,data in enumerate(data_loader):\n",
    "        output = model(data[0].to(device))\n",
    "        target = data[1].to(device)\n",
    "        predict = torch.argmax(output,dim=1)\n",
    "        correct = (predict == target - 1).sum().item()\n",
    "        sum_correct += correct\n",
    "    return sum_correct/len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ebca2aa-dc46-4669-ab5c-32decd7dce0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.93399339933994\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(validate(model,train_data_loader) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01d38723-fae3-4444-aaa4-47f82698d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(dir_path):\n",
    "    test_x = []\n",
    "    sort_csv_names = sorted(os.listdir(dir_path))\n",
    "    for csv_name in tqdm(sort_csv_names):\n",
    "        csv_path = os.path.join(dir_path,csv_name)\n",
    "        test_x.append(np.array(pd.read_csv(csv_path)).reshape((256,256,3)).transpose((2,0,1)))\n",
    "    return test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34319a05-dea5-44b3-a41e-8eff099822ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1712/1712 [00:30<00:00, 55.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# load test_x\n",
    "test_x = load_test_data(test_dir_path)\n",
    "test_x = np.array(test_x)\n",
    "test_dataset = TensorDataset(torch.FloatTensor(test_x))\n",
    "test_data_loader = DataLoader(dataset=test_dataset, batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97f4ef60-4d9f-4e3d-87f7-1a5b83fb3fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data_loader):\n",
    "    model.eval()\n",
    "    predict_array = []\n",
    "    for data in (data_loader):\n",
    "        output = model(data[0].to(device))\n",
    "        predict = torch.argmax(output,dim=1) + 1\n",
    "        predict_array += np.array(predict.cpu().detach()).tolist()\n",
    "    return predict_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d219941b-76d2-427e-8865-1f363701b05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Id  Category\n",
      "0     img_00000.csv        42\n",
      "1     img_00001.csv        10\n",
      "2     img_00002.csv        43\n",
      "3     img_00003.csv        42\n",
      "4     img_00004.csv        29\n",
      "...             ...       ...\n",
      "1707  img_01707.csv        97\n",
      "1708  img_01708.csv        29\n",
      "1709  img_01709.csv        32\n",
      "1710  img_01710.csv        88\n",
      "1711  img_01711.csv        98\n",
      "\n",
      "[1712 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    predict = predict(model,test_data_loader)\n",
    "    submission['Category'] = predict\n",
    "    print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a567efde-b407-475f-ab95-634aac622808",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9410a872-9832-402b-947a-683fa7a1a1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
