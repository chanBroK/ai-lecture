{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f5e0c96-41d9-4e9d-9285-e04a88536c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# cuda error 표시 안될 때 \n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb2b7357-27f0-4121-855c-da47ae6e1704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sklearn\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9369e3e6-249b-4e0d-97cd-a8606f91a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# set seed\n",
    "torch.manual_seed(1)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20f890e4-9919-4781-b4b5-d19442eeffa8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0              1\n",
      "0      1          Faces\n",
      "1      2     Faces_easy\n",
      "2      3       Leopards\n",
      "3      4     Motorbikes\n",
      "4      5      accordion\n",
      "..   ...            ...\n",
      "96    97     wheelchair\n",
      "97    98       wild_cat\n",
      "98    99  windsor_chair\n",
      "99   100         wrench\n",
      "100  101       yin_yang\n",
      "\n",
      "[101 rows x 2 columns]\n",
      "                 Id  Category\n",
      "0     img_00000.csv        42\n",
      "1     img_00001.csv        42\n",
      "2     img_00002.csv        42\n",
      "3     img_00003.csv        42\n",
      "4     img_00004.csv        42\n",
      "...             ...       ...\n",
      "1707  img_01707.csv        42\n",
      "1708  img_01708.csv        42\n",
      "1709  img_01709.csv        42\n",
      "1710  img_01710.csv        42\n",
      "1711  img_01711.csv        42\n",
      "\n",
      "[1712 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# csv load\n",
    "import os\n",
    "data_path = \"./2021-ai-w11-p1/\"\n",
    "labelname_csv_path = os.path.join(data_path,\"Label2Names.csv\")\n",
    "labelname = pd.read_csv(labelname_csv_path,header=None)\n",
    "print(labelname)\n",
    "train_dir_path = os.path.join(data_path,\"train_csv_v2\")\n",
    "test_dir_path = os.path.join(data_path,\"test_csv_v2\")\n",
    "submission = pd.read_csv(os.path.join(data_path,\"submission.csv\"))\n",
    "print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "beca87cb-6470-4c87-a1d1-fb63ef6fd2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,split,dir_path,transform,labelname):\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        if self.split == \"train\":\n",
    "            self.data_path = glob(os.path.join(dir_path,\"*\",\"*\"))\n",
    "            self.data_path = [x.replace(\"\\\\\",\"/\") for x in self.data_path if \"BACKGROUND_Google\" not in x]\n",
    "            self.label = [x.split(\"/\")[-2] for x in self.data_path]\n",
    "            self.label = [labelname.index[labelname[1] == x].tolist()[0] + 1 for x in self.label]\n",
    "        else:\n",
    "            self.data_path = glob(os.path.join(dir_path,\"*\"))\n",
    "            self.data_path = sorted(self.data_path)\n",
    "        self.len = len(self.data_path)\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    def __getitem__(self,index):\n",
    "        img = pd.read_csv(self.data_path[index]).to_numpy()\n",
    "        img = img.reshape(256,256,3)\n",
    "        img = img.transpose((2,0,1)).astype(np.int8)\n",
    "        img = torch.Tensor(img)\n",
    "        if self.split == \"train\":\n",
    "            return img, torch.LongTensor([self.label[index]])\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a93ac6b5-ce9e-44c2-8df9-21928a81df6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import transforms\n",
    "transform = transforms.Compose([transforms.Resize((256,256)),transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2ac33289-8f46-417a-9c5a-852461d8be07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256]) torch.Size([1]) tensor([5])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MyDataset(\"train\",train_dir_path,transform,labelname)\n",
    "x,y = train_dataset.__getitem__(1)\n",
    "print(x.shape, y.shape, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eff06a3f-b359-4691-ad01-c014e910aa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model load\n",
    "model = torchvision.models.vgg19(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False    \n",
    "model.classifier[6] = torch.nn.Linear(in_features=4096, out_features=101, bias=True)\n",
    "# init xavier\n",
    "# torch.nn.init.xavier_normal_(model.classifier[0].weight)\n",
    "# torch.nn.init.xavier_normal_(model.classifier[3].weight)\n",
    "torch.nn.init.xavier_normal_(model.classifier[6].weight)\n",
    "model = model.to(device)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1a4fd0f1-5717-41cf-867b-09aa4049bb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting param, optim, cost function,dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "lr = 1e-3\n",
    "batch_size = 16\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "train_data_loader = DataLoader(dataset=train_dataset, batch_size = batch_size, shuffle=True)\n",
    "epochs = 100\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2c8ff5a7-fa7c-4447-ab08-7c4539dfebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader):\n",
    "    model.train()\n",
    "    sum_cost = 0.0\n",
    "    sum_correct = 0\n",
    "    for i,data in enumerate(data_loader):\n",
    "        data, target = data[0].to(device),data[1].to(device).view(-1)\n",
    "        optim.zero_grad()\n",
    "        output = model(data)\n",
    "        cost = loss(output,target - 1)\n",
    "        predict = torch.argmax(output,dim=1)\n",
    "        correct = (predict == target - 1).sum().item()\n",
    "        sum_cost += cost.item()\n",
    "        sum_correct += correct\n",
    "        cost.backward()\n",
    "        optim.step()\n",
    "    return sum_cost/len(data_loader.dataset),sum_correct/len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fe49907b-1ed8-4126-8560-00ea2cf93ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.691008452613755 13.135313531353136\n",
      "1 1.783296510803424 30.825082508250823\n",
      "2 1.5056356272681712 39.30693069306931\n",
      "3 1.2614986295353854 44.554455445544555\n",
      "4 1.1702696587779735 49.43894389438944\n",
      "5 1.014270533586886 54.65346534653466\n",
      "6 0.9437547088062802 57.95379537953795\n",
      "7 0.9107904307519642 58.97689768976898\n",
      "8 0.8517425039813857 62.277227722772274\n",
      "9 0.8132147947836532 62.90429042904291\n",
      "10 0.8078668486167102 64.12541254125412\n",
      "11 0.7795673911721006 64.91749174917491\n",
      "12 0.7556818768529608 66.8976897689769\n",
      "13 0.7297501772554535 67.98679867986799\n",
      "14 0.7119215277653717 67.49174917491749\n",
      "15 0.713341240835662 69.10891089108911\n",
      "16 0.6604241651719552 70.23102310231023\n",
      "17 0.670043515155769 71.25412541254126\n",
      "18 0.640895585976418 72.60726072607261\n",
      "19 0.6552522220873006 73.53135313531352\n",
      "20 0.5755583869528468 74.52145214521451\n",
      "21 0.6153341933201788 73.96039603960396\n",
      "22 0.6223283769807143 74.38943894389439\n",
      "23 0.6326249817619869 74.22442244224422\n",
      "24 0.5861056920122539 75.47854785478549\n",
      "25 0.6237314517435983 75.08250825082509\n",
      "26 0.6174237467084516 76.83168316831683\n",
      "27 0.6178694987729716 75.8085808580858\n",
      "28 0.5968594494784856 76.3036303630363\n",
      "29 0.6460446752198928 75.77557755775578\n",
      "30 0.5098428091138798 79.24092409240924\n",
      "31 0.5845647442954017 78.01980198019803\n",
      "32 0.6015414269916027 78.18481848184818\n",
      "33 0.523161391619823 79.20792079207921\n",
      "34 0.5729262841028337 79.37293729372938\n",
      "35 0.5696538590201325 78.74587458745874\n",
      "36 0.5653948644687692 79.40594059405942\n",
      "37 0.5187008286574746 79.60396039603961\n",
      "38 0.5364916700425268 79.9009900990099\n",
      "39 0.5708206836671573 79.14191419141913\n",
      "40 0.5772554868618106 79.70297029702971\n",
      "41 0.5646363226444446 79.40594059405942\n",
      "42 0.5728154690105076 79.50495049504951\n",
      "43 0.5049943496053574 81.25412541254126\n",
      "44 0.4971629594153592 82.34323432343234\n",
      "45 0.48170249360180895 82.67326732673267\n",
      "46 0.49372618066053303 81.58415841584159\n",
      "47 0.5232647949034341 81.51815181518151\n",
      "48 0.5094737070539215 82.64026402640265\n",
      "49 0.502443563919555 81.94719471947195\n",
      "50 0.535040517668921 82.2112211221122\n",
      "51 0.47875689453455056 82.34323432343234\n",
      "52 0.5272684589092571 81.58415841584159\n",
      "53 0.4640340646676843 82.83828382838284\n",
      "54 0.548354691259685 82.50825082508251\n",
      "55 0.5339555315083848 82.54125412541255\n",
      "56 0.46538897724369277 84.42244224422443\n",
      "57 0.5336754683371835 82.83828382838284\n",
      "58 0.5637767142319129 81.81518151815182\n",
      "59 0.4577574236540854 84.48844884488449\n",
      "60 0.5064934249997027 83.6963696369637\n",
      "61 0.4862745485821281 83.96039603960396\n",
      "62 0.5063687799393742 83.3993399339934\n",
      "63 0.47513079914590667 84.0924092409241\n",
      "64 0.4530060551713783 84.55445544554455\n",
      "65 0.5112901051658216 82.64026402640265\n",
      "66 0.4829011097933712 83.3003300330033\n",
      "67 0.5285159963922017 84.22442244224423\n",
      "68 0.4739734972313701 84.98349834983499\n",
      "69 0.45282654580702053 85.64356435643565\n",
      "70 0.5251919853596294 83.3003300330033\n",
      "71 0.4868031368545433 84.42244224422443\n",
      "72 0.5060837141446519 84.88448844884489\n",
      "73 0.5682236035937881 82.8052805280528\n",
      "74 0.5441735738218011 83.33333333333334\n",
      "75 0.4805524632000663 85.11551155115512\n",
      "76 0.48538262604025795 84.81848184818482\n",
      "77 0.47117944861302774 86.1056105610561\n",
      "78 0.4449409902469881 85.74257425742574\n",
      "79 0.47278553815479835 85.31353135313532\n",
      "80 0.4993489494459364 85.47854785478548\n",
      "81 0.49206766658280054 85.97359735973598\n",
      "82 0.4419503593268772 86.4026402640264\n",
      "83 0.5027369844330045 85.21452145214522\n",
      "84 0.37905918710396747 86.27062706270627\n",
      "85 0.46932208944175136 85.94059405940594\n",
      "86 0.5216725284314819 85.57755775577559\n",
      "87 0.49454255797523133 85.87458745874588\n",
      "88 0.4738007567378119 85.7095709570957\n",
      "89 0.4747207943421625 85.67656765676568\n",
      "90 0.4414097414820448 86.43564356435644\n",
      "91 0.4598056096529451 86.89768976897689\n",
      "92 0.3941260062189602 87.75577557755776\n",
      "93 0.4398750692881644 87.12871287128714\n",
      "94 0.4576159563444263 86.2046204620462\n",
      "95 0.45332043716381804 87.16171617161717\n",
      "96 0.419375948382577 86.99669966996699\n",
      "97 0.4516461671648683 87.35973597359737\n",
      "98 0.44655676071831074 86.56765676567657\n",
      "99 0.4862926999520424 86.43564356435644\n",
      "endtime = 6413.937526226044\n"
     ]
    }
   ],
   "source": [
    "#train \n",
    "import time\n",
    "cur_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    cost,acc = train(model,train_data_loader)\n",
    "    print(epoch,cost,acc * 100)\n",
    "print(\"endtime =\",time.time() - cur_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8fe206c4-c0bd-4ab7-a9a4-10bd4bc83e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data_loader):\n",
    "    model.eval()\n",
    "    sum_correct = 0\n",
    "    for i,data in enumerate(data_loader):\n",
    "        output = model(data[0].to(device))\n",
    "        target = data[1].to(device).view(-1)\n",
    "        predict = torch.argmax(output,dim=1)\n",
    "        correct = (predict == target - 1).sum().item()\n",
    "        sum_correct += correct\n",
    "    return sum_correct/len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9ebca2aa-dc46-4669-ab5c-32decd7dce0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.96699669966996\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(validate(model,train_data_loader) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "34319a05-dea5-44b3-a41e-8eff099822ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test_x\n",
    "test_dataset = MyDataset(\"test\",test_dir_path,transform,labelname)\n",
    "test_data_loader = DataLoader(dataset=test_dataset, batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f51f1107-640a-4bc9-8a77-3385154f97ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "x = test_dataset.__getitem__(1)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "97f4ef60-4d9f-4e3d-87f7-1a5b83fb3fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data_loader):\n",
    "    model.eval()\n",
    "    predict_array = []\n",
    "    for data in data_loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        predict = torch.argmax(output,dim=1) + 1\n",
    "        predict_array += np.array(predict.cpu().detach()).tolist()\n",
    "    return predict_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d219941b-76d2-427e-8865-1f363701b05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Id  Category\n",
      "0     img_00000.csv        42\n",
      "1     img_00001.csv        42\n",
      "2     img_00002.csv        43\n",
      "3     img_00003.csv        52\n",
      "4     img_00004.csv        43\n",
      "...             ...       ...\n",
      "1707  img_01707.csv        97\n",
      "1708  img_01708.csv        11\n",
      "1709  img_01709.csv        98\n",
      "1710  img_01710.csv        98\n",
      "1711  img_01711.csv        82\n",
      "\n",
      "[1712 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    predict = predict(model,test_data_loader)\n",
    "    submission['Category'] = predict\n",
    "    print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a567efde-b407-475f-ab95-634aac622808",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9410a872-9832-402b-947a-683fa7a1a1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
