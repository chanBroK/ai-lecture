{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46fabc5-99fe-4a3f-8e94-d0de65ef3ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6d95b26-09ac-417b-b67d-f9007a326bd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2aa91e5ac30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "# For reproducibility\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32a251e2-e8fe-4122-8d09-86224c9483ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       year  avgTemp  minTemp  maxTemp  rainFall  avgPrice\n",
      "0  20100101     -4.9    -11.0      0.9       0.0      2123\n",
      "1  20100102     -3.1     -5.5      5.5       0.8      2123\n",
      "2  20100103     -2.9     -6.9      1.4       0.0      2123\n",
      "3  20100104     -1.8     -5.1      2.2       5.9      2020\n",
      "4  20100105     -5.2     -8.7     -1.8       0.7      2060\n",
      "       year  avgTemp  minTemp  maxTemp  rainFall\n",
      "0  20170107      4.0     -1.4      9.5       0.1\n",
      "1  20170120     -1.7     -5.4      1.4       3.3\n",
      "2  20170223      1.4     -2.0      5.0       0.0\n",
      "3  20170227      3.6     -2.5     11.1       0.1\n",
      "4  20170309      5.0     -1.6     11.3       0.0\n",
      "   Id   Expected\n",
      "0   0  2997.8792\n",
      "1   1  2777.1380\n",
      "2   2  2868.9387\n",
      "3   3  3113.0390\n",
      "4   4  3039.6218\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(\"/kaggle/input/2021-ai-w3-p1/train.csv\")\n",
    "train_df = pd.read_csv(\"./배추가격예측_data/train.csv\")\n",
    "test_df = pd.read_csv(\"./배추가격예측_data/test.csv\")\n",
    "submit_df = pd.read_csv(\"./배추가격예측_data/submit_sample.csv\")\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n",
    "print(submit_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "907c3cf1-7cea-4416-bd53-ce4c1bc4e36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2557, 4])\n",
      "torch.Size([2557])\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([train_df['avgTemp'],train_df['minTemp'],train_df['maxTemp'],train_df['rainFall']])\n",
    "x_train = x_train.T\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.FloatTensor(train_df['avgPrice'])\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02ce1e67-548b-4c6d-9ec0-123481cfe15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/10000 w:tensor([[0.8280],\n",
      "        [0.5309],\n",
      "        [1.1705],\n",
      "        [0.2273]], requires_grad=True) b: 0.064 Cost: 12013343.000000\n",
      "Epoch  100/10000 w:tensor([[38.5997],\n",
      "        [18.9156],\n",
      "        [60.9042],\n",
      "        [10.6542]], requires_grad=True) b: 4.136 Cost: 5126071.000000\n",
      "Epoch  200/10000 w:tensor([[43.5992],\n",
      "        [12.3714],\n",
      "        [78.5713],\n",
      "        [12.2778]], requires_grad=True) b: 6.470 Cost: 4694184.500000\n",
      "Epoch  300/10000 w:tensor([[42.9296],\n",
      "        [ 1.9272],\n",
      "        [88.5235],\n",
      "        [12.5497]], requires_grad=True) b: 8.439 Cost: 4480125.000000\n",
      "Epoch  400/10000 w:tensor([[41.3259],\n",
      "        [-8.7644],\n",
      "        [96.7853],\n",
      "        [12.7394]], requires_grad=True) b: 10.286 Cost: 4291323.000000\n",
      "Epoch  500/10000 w:tensor([[ 39.6146],\n",
      "        [-19.0860],\n",
      "        [104.4289],\n",
      "        [ 13.0407]], requires_grad=True) b: 12.055 Cost: 4120052.250000\n",
      "Epoch  600/10000 w:tensor([[ 37.9385],\n",
      "        [-28.9494],\n",
      "        [111.6601],\n",
      "        [ 13.4636]], requires_grad=True) b: 13.758 Cost: 3964444.500000\n",
      "Epoch  700/10000 w:tensor([[ 36.3214],\n",
      "        [-38.3579],\n",
      "        [118.5318],\n",
      "        [ 13.9895]], requires_grad=True) b: 15.399 Cost: 3822992.250000\n",
      "Epoch  800/10000 w:tensor([[ 34.7659],\n",
      "        [-47.3299],\n",
      "        [125.0690],\n",
      "        [ 14.5980]], requires_grad=True) b: 16.981 Cost: 3694352.750000\n",
      "Epoch  900/10000 w:tensor([[ 33.2709],\n",
      "        [-55.8854],\n",
      "        [131.2907],\n",
      "        [ 15.2708]], requires_grad=True) b: 18.506 Cost: 3577325.250000\n",
      "Epoch 1000/10000 w:tensor([[ 31.8346],\n",
      "        [-64.0441],\n",
      "        [137.2139],\n",
      "        [ 15.9925]], requires_grad=True) b: 19.978 Cost: 3470830.750000\n",
      "Epoch 1100/10000 w:tensor([[ 30.4550],\n",
      "        [-71.8245],\n",
      "        [142.8545],\n",
      "        [ 16.7499]], requires_grad=True) b: 21.399 Cost: 3373898.500000\n",
      "Epoch 1200/10000 w:tensor([[ 29.1304],\n",
      "        [-79.2444],\n",
      "        [148.2270],\n",
      "        [ 17.5320]], requires_grad=True) b: 22.771 Cost: 3285652.750000\n",
      "Epoch 1300/10000 w:tensor([[ 27.8586],\n",
      "        [-86.3205],\n",
      "        [153.3454],\n",
      "        [ 18.3295]], requires_grad=True) b: 24.097 Cost: 3205301.000000\n",
      "Epoch 1400/10000 w:tensor([[ 26.6377],\n",
      "        [-93.0689],\n",
      "        [158.2225],\n",
      "        [ 19.1348]], requires_grad=True) b: 25.378 Cost: 3132127.000000\n",
      "Epoch 1500/10000 w:tensor([[ 25.4659],\n",
      "        [-99.5048],\n",
      "        [162.8707],\n",
      "        [ 19.9415]], requires_grad=True) b: 26.618 Cost: 3065482.000000\n",
      "Epoch 1600/10000 w:tensor([[  24.3413],\n",
      "        [-105.6428],\n",
      "        [ 167.3013],\n",
      "        [  20.7442]], requires_grad=True) b: 27.816 Cost: 3004777.250000\n",
      "Epoch 1700/10000 w:tensor([[  23.2620],\n",
      "        [-111.4967],\n",
      "        [ 171.5250],\n",
      "        [  21.5386]], requires_grad=True) b: 28.977 Cost: 2949477.750000\n",
      "Epoch 1800/10000 w:tensor([[  22.2262],\n",
      "        [-117.0794],\n",
      "        [ 175.5522],\n",
      "        [  22.3211]], requires_grad=True) b: 30.101 Cost: 2899099.000000\n",
      "Epoch 1900/10000 w:tensor([[  21.2321],\n",
      "        [-122.4037],\n",
      "        [ 179.3924],\n",
      "        [  23.0891]], requires_grad=True) b: 31.190 Cost: 2853200.000000\n",
      "Epoch 2000/10000 w:tensor([[  20.2781],\n",
      "        [-127.4815],\n",
      "        [ 183.0547],\n",
      "        [  23.8402]], requires_grad=True) b: 32.246 Cost: 2811379.000000\n",
      "Epoch 2100/10000 w:tensor([[  19.3626],\n",
      "        [-132.3240],\n",
      "        [ 186.5477],\n",
      "        [  24.5727]], requires_grad=True) b: 33.269 Cost: 2773271.000000\n",
      "Epoch 2200/10000 w:tensor([[  18.4838],\n",
      "        [-136.9420],\n",
      "        [ 189.8795],\n",
      "        [  25.2853]], requires_grad=True) b: 34.263 Cost: 2738546.000000\n",
      "Epoch 2300/10000 w:tensor([[  17.6403],\n",
      "        [-141.3460],\n",
      "        [ 193.0578],\n",
      "        [  25.9771]], requires_grad=True) b: 35.228 Cost: 2706901.250000\n",
      "Epoch 2400/10000 w:tensor([[  16.8306],\n",
      "        [-145.5458],\n",
      "        [ 196.0900],\n",
      "        [  26.6473]], requires_grad=True) b: 36.165 Cost: 2678060.750000\n",
      "Epoch 2500/10000 w:tensor([[  16.0531],\n",
      "        [-149.5507],\n",
      "        [ 198.9830],\n",
      "        [  27.2955]], requires_grad=True) b: 37.075 Cost: 2651775.500000\n",
      "Epoch 2600/10000 w:tensor([[  15.3066],\n",
      "        [-153.3695],\n",
      "        [ 201.7433],\n",
      "        [  27.9216]], requires_grad=True) b: 37.961 Cost: 2627818.500000\n",
      "Epoch 2700/10000 w:tensor([[  14.5897],\n",
      "        [-157.0110],\n",
      "        [ 204.3771],\n",
      "        [  28.5256]], requires_grad=True) b: 38.822 Cost: 2605980.750000\n",
      "Epoch 2800/10000 w:tensor([[  13.9011],\n",
      "        [-160.4832],\n",
      "        [ 206.8905],\n",
      "        [  29.1074]], requires_grad=True) b: 39.661 Cost: 2586074.250000\n",
      "Epoch 2900/10000 w:tensor([[  13.2395],\n",
      "        [-163.7937],\n",
      "        [ 209.2891],\n",
      "        [  29.6675]], requires_grad=True) b: 40.478 Cost: 2567927.000000\n",
      "Epoch 3000/10000 w:tensor([[  12.6038],\n",
      "        [-166.9503],\n",
      "        [ 211.5782],\n",
      "        [  30.2060]], requires_grad=True) b: 41.273 Cost: 2551381.750000\n",
      "Epoch 3100/10000 w:tensor([[  11.9929],\n",
      "        [-169.9597],\n",
      "        [ 213.7628],\n",
      "        [  30.7235]], requires_grad=True) b: 42.049 Cost: 2536296.500000\n",
      "Epoch 3200/10000 w:tensor([[  11.4056],\n",
      "        [-172.8286],\n",
      "        [ 215.8479],\n",
      "        [  31.2203]], requires_grad=True) b: 42.806 Cost: 2522541.250000\n",
      "Epoch 3300/10000 w:tensor([[  10.8410],\n",
      "        [-175.5636],\n",
      "        [ 217.8381],\n",
      "        [  31.6969]], requires_grad=True) b: 43.545 Cost: 2509997.000000\n",
      "Epoch 3400/10000 w:tensor([[  10.2979],\n",
      "        [-178.1707],\n",
      "        [ 219.7378],\n",
      "        [  32.1540]], requires_grad=True) b: 44.267 Cost: 2498557.000000\n",
      "Epoch 3500/10000 w:tensor([[   9.7755],\n",
      "        [-180.6558],\n",
      "        [ 221.5511],\n",
      "        [  32.5921]], requires_grad=True) b: 44.972 Cost: 2488122.250000\n",
      "Epoch 3600/10000 w:tensor([[   9.2728],\n",
      "        [-183.0245],\n",
      "        [ 223.2821],\n",
      "        [  33.0118]], requires_grad=True) b: 45.661 Cost: 2478603.250000\n",
      "Epoch 3700/10000 w:tensor([[   8.7889],\n",
      "        [-185.2821],\n",
      "        [ 224.9346],\n",
      "        [  33.4136]], requires_grad=True) b: 46.335 Cost: 2469918.250000\n",
      "Epoch 3800/10000 w:tensor([[   8.3230],\n",
      "        [-187.4335],\n",
      "        [ 226.5121],\n",
      "        [  33.7983]], requires_grad=True) b: 46.995 Cost: 2461994.000000\n",
      "Epoch 3900/10000 w:tensor([[   7.8743],\n",
      "        [-189.4838],\n",
      "        [ 228.0180],\n",
      "        [  34.1663]], requires_grad=True) b: 47.641 Cost: 2454762.000000\n",
      "Epoch 4000/10000 w:tensor([[   7.4420],\n",
      "        [-191.4374],\n",
      "        [ 229.4557],\n",
      "        [  34.5183]], requires_grad=True) b: 48.274 Cost: 2448161.000000\n",
      "Epoch 4100/10000 w:tensor([[   7.0255],\n",
      "        [-193.2989],\n",
      "        [ 230.8284],\n",
      "        [  34.8550]], requires_grad=True) b: 48.895 Cost: 2442134.750000\n",
      "Epoch 4200/10000 w:tensor([[   6.6239],\n",
      "        [-195.0723],\n",
      "        [ 232.1389],\n",
      "        [  35.1768]], requires_grad=True) b: 49.504 Cost: 2436632.250000\n",
      "Epoch 4300/10000 w:tensor([[   6.2366],\n",
      "        [-196.7618],\n",
      "        [ 233.3902],\n",
      "        [  35.4843]], requires_grad=True) b: 50.101 Cost: 2431606.500000\n",
      "Epoch 4400/10000 w:tensor([[   5.8630],\n",
      "        [-198.3711],\n",
      "        [ 234.5849],\n",
      "        [  35.7782]], requires_grad=True) b: 50.687 Cost: 2427015.750000\n",
      "Epoch 4500/10000 w:tensor([[   5.5024],\n",
      "        [-199.9039],\n",
      "        [ 235.7257],\n",
      "        [  36.0590]], requires_grad=True) b: 51.263 Cost: 2422820.750000\n",
      "Epoch 4600/10000 w:tensor([[   5.1543],\n",
      "        [-201.3637],\n",
      "        [ 236.8151],\n",
      "        [  36.3271]], requires_grad=True) b: 51.829 Cost: 2418986.250000\n",
      "Epoch 4700/10000 w:tensor([[   4.8181],\n",
      "        [-202.7538],\n",
      "        [ 237.8553],\n",
      "        [  36.5832]], requires_grad=True) b: 52.386 Cost: 2415480.250000\n",
      "Epoch 4800/10000 w:tensor([[   4.4932],\n",
      "        [-204.0774],\n",
      "        [ 238.8486],\n",
      "        [  36.8277]], requires_grad=True) b: 52.934 Cost: 2412273.750000\n",
      "Epoch 4900/10000 w:tensor([[   4.1792],\n",
      "        [-205.3374],\n",
      "        [ 239.7971],\n",
      "        [  37.0611]], requires_grad=True) b: 53.473 Cost: 2409340.250000\n",
      "Epoch 5000/10000 w:tensor([[   3.8755],\n",
      "        [-206.5370],\n",
      "        [ 240.7030],\n",
      "        [  37.2839]], requires_grad=True) b: 54.004 Cost: 2406655.000000\n",
      "Epoch 5100/10000 w:tensor([[   3.5817],\n",
      "        [-207.6787],\n",
      "        [ 241.5681],\n",
      "        [  37.4965]], requires_grad=True) b: 54.526 Cost: 2404195.750000\n",
      "Epoch 5200/10000 w:tensor([[   3.2974],\n",
      "        [-208.7652],\n",
      "        [ 242.3944],\n",
      "        [  37.6994]], requires_grad=True) b: 55.042 Cost: 2401943.250000\n",
      "Epoch 5300/10000 w:tensor([[   3.0220],\n",
      "        [-209.7991],\n",
      "        [ 243.1835],\n",
      "        [  37.8930]], requires_grad=True) b: 55.550 Cost: 2399878.000000\n",
      "Epoch 5400/10000 w:tensor([[   2.7553],\n",
      "        [-210.7826],\n",
      "        [ 243.9372],\n",
      "        [  38.0776]], requires_grad=True) b: 56.052 Cost: 2397984.750000\n",
      "Epoch 5500/10000 w:tensor([[   2.4968],\n",
      "        [-211.7182],\n",
      "        [ 244.6571],\n",
      "        [  38.2538]], requires_grad=True) b: 56.547 Cost: 2396246.750000\n",
      "Epoch 5600/10000 w:tensor([[   2.2461],\n",
      "        [-212.6079],\n",
      "        [ 245.3447],\n",
      "        [  38.4218]], requires_grad=True) b: 57.035 Cost: 2394651.000000\n",
      "Epoch 5700/10000 w:tensor([[   2.0029],\n",
      "        [-213.4540],\n",
      "        [ 246.0015],\n",
      "        [  38.5820]], requires_grad=True) b: 57.518 Cost: 2393184.750000\n",
      "Epoch 5800/10000 w:tensor([[   1.7669],\n",
      "        [-214.2583],\n",
      "        [ 246.6290],\n",
      "        [  38.7348]], requires_grad=True) b: 57.995 Cost: 2391836.500000\n",
      "Epoch 5900/10000 w:tensor([[   1.5376],\n",
      "        [-215.0229],\n",
      "        [ 247.2284],\n",
      "        [  38.8805]], requires_grad=True) b: 58.467 Cost: 2390595.750000\n",
      "Epoch 6000/10000 w:tensor([[   1.3150],\n",
      "        [-215.7494],\n",
      "        [ 247.8010],\n",
      "        [  39.0194]], requires_grad=True) b: 58.933 Cost: 2389452.750000\n",
      "Epoch 6100/10000 w:tensor([[   1.0985],\n",
      "        [-216.4396],\n",
      "        [ 248.3481],\n",
      "        [  39.1518]], requires_grad=True) b: 59.395 Cost: 2388398.750000\n",
      "Epoch 6200/10000 w:tensor([[   0.8879],\n",
      "        [-217.0952],\n",
      "        [ 248.8708],\n",
      "        [  39.2779]], requires_grad=True) b: 59.852 Cost: 2387425.750000\n",
      "Epoch 6300/10000 w:tensor([[   0.6831],\n",
      "        [-217.7178],\n",
      "        [ 249.3702],\n",
      "        [  39.3982]], requires_grad=True) b: 60.304 Cost: 2386527.250000\n",
      "Epoch 6400/10000 w:tensor([[   0.4836],\n",
      "        [-218.3088],\n",
      "        [ 249.8474],\n",
      "        [  39.5128]], requires_grad=True) b: 60.752 Cost: 2385696.000000\n",
      "Epoch 6500/10000 w:tensor([[   0.2894],\n",
      "        [-218.8697],\n",
      "        [ 250.3033],\n",
      "        [  39.6219]], requires_grad=True) b: 61.196 Cost: 2384926.250000\n",
      "Epoch 6600/10000 w:tensor([[ 1.0003e-01],\n",
      "        [-2.1940e+02],\n",
      "        [ 2.5074e+02],\n",
      "        [ 3.9726e+01]], requires_grad=True) b: 61.636 Cost: 2384212.250000\n",
      "Epoch 6700/10000 w:tensor([[-8.4593e-02],\n",
      "        [-2.1991e+02],\n",
      "        [ 2.5116e+02],\n",
      "        [ 3.9825e+01]], requires_grad=True) b: 62.072 Cost: 2383549.500000\n",
      "Epoch 6800/10000 w:tensor([[  -0.2647],\n",
      "        [-220.3853],\n",
      "        [ 251.5535],\n",
      "        [  39.9194]], requires_grad=True) b: 62.505 Cost: 2382933.000000\n",
      "Epoch 6900/10000 w:tensor([[  -0.4406],\n",
      "        [-220.8389],\n",
      "        [ 251.9339],\n",
      "        [  40.0093]], requires_grad=True) b: 62.934 Cost: 2382359.000000\n",
      "Epoch 7000/10000 w:tensor([[  -0.6123],\n",
      "        [-221.2686],\n",
      "        [ 252.2975],\n",
      "        [  40.0949]], requires_grad=True) b: 63.360 Cost: 2381823.750000\n",
      "Epoch 7100/10000 w:tensor([[  -0.7801],\n",
      "        [-221.6757],\n",
      "        [ 252.6451],\n",
      "        [  40.1763]], requires_grad=True) b: 63.782 Cost: 2381323.500000\n",
      "Epoch 7200/10000 w:tensor([[  -0.9442],\n",
      "        [-222.0609],\n",
      "        [ 252.9773],\n",
      "        [  40.2539]], requires_grad=True) b: 64.202 Cost: 2380855.000000\n",
      "Epoch 7300/10000 w:tensor([[  -1.1047],\n",
      "        [-222.4255],\n",
      "        [ 253.2950],\n",
      "        [  40.3277]], requires_grad=True) b: 64.619 Cost: 2380415.750000\n",
      "Epoch 7400/10000 w:tensor([[  -1.2618],\n",
      "        [-222.7702],\n",
      "        [ 253.5986],\n",
      "        [  40.3980]], requires_grad=True) b: 65.034 Cost: 2380003.250000\n",
      "Epoch 7500/10000 w:tensor([[  -1.4156],\n",
      "        [-223.0961],\n",
      "        [ 253.8890],\n",
      "        [  40.4648]], requires_grad=True) b: 65.445 Cost: 2379614.750000\n",
      "Epoch 7600/10000 w:tensor([[  -1.5663],\n",
      "        [-223.4040],\n",
      "        [ 254.1667],\n",
      "        [  40.5284]], requires_grad=True) b: 65.854 Cost: 2379248.500000\n",
      "Epoch 7700/10000 w:tensor([[  -1.7141],\n",
      "        [-223.6947],\n",
      "        [ 254.4323],\n",
      "        [  40.5889]], requires_grad=True) b: 66.261 Cost: 2378902.500000\n",
      "Epoch 7800/10000 w:tensor([[  -1.8590],\n",
      "        [-223.9689],\n",
      "        [ 254.6863],\n",
      "        [  40.6464]], requires_grad=True) b: 66.666 Cost: 2378574.500000\n",
      "Epoch 7900/10000 w:tensor([[  -2.0012],\n",
      "        [-224.2275],\n",
      "        [ 254.9292],\n",
      "        [  40.7011]], requires_grad=True) b: 67.068 Cost: 2378263.250000\n",
      "Epoch 8000/10000 w:tensor([[  -2.1409],\n",
      "        [-224.4711],\n",
      "        [ 255.1616],\n",
      "        [  40.7530]], requires_grad=True) b: 67.469 Cost: 2377967.500000\n",
      "Epoch 8100/10000 w:tensor([[  -2.2780],\n",
      "        [-224.7004],\n",
      "        [ 255.3840],\n",
      "        [  40.8025]], requires_grad=True) b: 67.867 Cost: 2377685.250000\n",
      "Epoch 8200/10000 w:tensor([[  -2.4129],\n",
      "        [-224.9161],\n",
      "        [ 255.5967],\n",
      "        [  40.8494]], requires_grad=True) b: 68.264 Cost: 2377415.500000\n",
      "Epoch 8300/10000 w:tensor([[  -2.5454],\n",
      "        [-225.1188],\n",
      "        [ 255.8003],\n",
      "        [  40.8940]], requires_grad=True) b: 68.658 Cost: 2377157.750000\n",
      "Epoch 8400/10000 w:tensor([[  -2.6758],\n",
      "        [-225.3091],\n",
      "        [ 255.9950],\n",
      "        [  40.9363]], requires_grad=True) b: 69.051 Cost: 2376910.250000\n",
      "Epoch 8500/10000 w:tensor([[  -2.8041],\n",
      "        [-225.4876],\n",
      "        [ 256.1814],\n",
      "        [  40.9765]], requires_grad=True) b: 69.442 Cost: 2376672.250000\n",
      "Epoch 8600/10000 w:tensor([[  -2.9305],\n",
      "        [-225.6547],\n",
      "        [ 256.3599],\n",
      "        [  41.0147]], requires_grad=True) b: 69.832 Cost: 2376443.000000\n",
      "Epoch 8700/10000 w:tensor([[  -3.0550],\n",
      "        [-225.8111],\n",
      "        [ 256.5307],\n",
      "        [  41.0509]], requires_grad=True) b: 70.220 Cost: 2376221.750000\n",
      "Epoch 8800/10000 w:tensor([[  -3.1777],\n",
      "        [-225.9572],\n",
      "        [ 256.6944],\n",
      "        [  41.0853]], requires_grad=True) b: 70.607 Cost: 2376008.000000\n",
      "Epoch 8900/10000 w:tensor([[  -3.2987],\n",
      "        [-226.0934],\n",
      "        [ 256.8509],\n",
      "        [  41.1178]], requires_grad=True) b: 70.993 Cost: 2375800.500000\n",
      "Epoch 9000/10000 w:tensor([[  -3.4180],\n",
      "        [-226.2202],\n",
      "        [ 257.0009],\n",
      "        [  41.1487]], requires_grad=True) b: 71.377 Cost: 2375599.000000\n",
      "Epoch 9100/10000 w:tensor([[  -3.5358],\n",
      "        [-226.3382],\n",
      "        [ 257.1446],\n",
      "        [  41.1780]], requires_grad=True) b: 71.760 Cost: 2375403.250000\n",
      "Epoch 9200/10000 w:tensor([[  -3.6521],\n",
      "        [-226.4475],\n",
      "        [ 257.2822],\n",
      "        [  41.2057]], requires_grad=True) b: 72.141 Cost: 2375212.250000\n",
      "Epoch 9300/10000 w:tensor([[  -3.7670],\n",
      "        [-226.5487],\n",
      "        [ 257.4142],\n",
      "        [  41.2319]], requires_grad=True) b: 72.522 Cost: 2375026.000000\n",
      "Epoch 9400/10000 w:tensor([[  -3.8805],\n",
      "        [-226.6421],\n",
      "        [ 257.5407],\n",
      "        [  41.2567]], requires_grad=True) b: 72.901 Cost: 2374843.500000\n",
      "Epoch 9500/10000 w:tensor([[  -3.9927],\n",
      "        [-226.7281],\n",
      "        [ 257.6617],\n",
      "        [  41.2802]], requires_grad=True) b: 73.280 Cost: 2374665.000000\n",
      "Epoch 9600/10000 w:tensor([[  -4.1037],\n",
      "        [-226.8071],\n",
      "        [ 257.7779],\n",
      "        [  41.3024]], requires_grad=True) b: 73.657 Cost: 2374490.000000\n",
      "Epoch 9700/10000 w:tensor([[  -4.2135],\n",
      "        [-226.8792],\n",
      "        [ 257.8892],\n",
      "        [  41.3234]], requires_grad=True) b: 74.033 Cost: 2374318.500000\n",
      "Epoch 9800/10000 w:tensor([[  -4.3221],\n",
      "        [-226.9449],\n",
      "        [ 257.9960],\n",
      "        [  41.3431]], requires_grad=True) b: 74.409 Cost: 2374149.250000\n",
      "Epoch 9900/10000 w:tensor([[  -4.4297],\n",
      "        [-227.0044],\n",
      "        [ 258.0984],\n",
      "        [  41.3618]], requires_grad=True) b: 74.784 Cost: 2373983.000000\n",
      "Epoch 10000/10000 w:tensor([[  -4.5362],\n",
      "        [-227.0581],\n",
      "        [ 258.1969],\n",
      "        [  41.3794]], requires_grad=True) b: 75.157 Cost: 2373819.250000\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "w = torch.zeros((4,1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([w, b], lr=1e-5)\n",
    "\n",
    "nb_epochs = 10000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    hypothesis = x_train.matmul(w) + b\n",
    "\n",
    "    # cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 1000 == 0:\n",
    "        print('Epoch {:4d}/{} w:{} b: {:.3f} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, w, b.item(), cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dde232cc-fc36-4b01-a857-1ac7c6fd2e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2831.9026],\n",
      "        [1807.0104],\n",
      "        [1813.9073],\n",
      "        [3496.5962],\n",
      "        [3333.3945],\n",
      "        [3423.5461],\n",
      "        [2954.6296],\n",
      "        [4435.4043],\n",
      "        [3648.7839],\n",
      "        [4609.3984],\n",
      "        [2082.8289],\n",
      "        [3873.0354],\n",
      "        [2948.1047],\n",
      "        [3181.6604],\n",
      "        [2435.9592],\n",
      "        [3548.2068],\n",
      "        [3471.8418],\n",
      "        [4436.1060],\n",
      "        [3123.7905],\n",
      "        [3485.6868],\n",
      "        [2437.1670],\n",
      "        [2811.8064],\n",
      "        [3217.7251],\n",
      "        [1590.9962]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x_test = torch.FloatTensor(np.array([test_df['avgTemp'],test_df['minTemp'],test_df['maxTemp'],test_df['rainFall']]).T)\n",
    "y_test = x_test.matmul(w)+ b\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d3175c5-f404-4485-979b-31a1edc13998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2831.902588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1807.010376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1813.907349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3496.596191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3333.394531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id     Expected\n",
       "0   0  2831.902588\n",
       "1   1  1807.010376\n",
       "2   2  1813.907349\n",
       "3   3  3496.596191\n",
       "4   4  3333.394531"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df['Expected'] = y_test.detach().numpy()\n",
    "submit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "941763b8-dff6-469c-9440-0cbf3a5049ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.to_csv(\"./배추가격예측_data/submit_sample.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a717866e-fd7b-42c3-a11d-d9365b47c0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
